{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d97755",
   "metadata": {},
   "source": [
    "# 모델 레이어 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a7c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, activations, losses, optimizers, metrics\n",
    "\n",
    "def create_yolo():\n",
    "\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(layers.Convolution2D(64, (7, 7), strides=(2, 2), input_shape=(448, 448, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "    # Block 2\n",
    "    model.add(layers.Convolution2D(192, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(layers.Convolution2D(128, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(256, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "    \n",
    "    # Block 4\n",
    "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(256, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(512, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(512, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(1024, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "    # Block 5\n",
    "    model.add(layers.Convolution2D(512, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(1024, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(512, (1, 1), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(1024, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(1024, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(1024, (3, 3), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    # Block 6\n",
    "    model.add(layers.Convolution2D(1024, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Convolution2D(1024, (3, 3), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(7 * 7 * 30))\n",
    "    model.add(layers.Reshape(target_shape=(7, 7, 30)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72aebad",
   "metadata": {},
   "source": [
    "# Pascal VOC 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy\n",
    "import xml.etree.ElementTree as ET\n",
    "import tqdm\n",
    "\n",
    "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, \n",
    "               'bus': 5, 'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, \n",
    "               'diningtable': 10, 'dog': 11, 'horse': 12, 'motorbike': 13, 'person': 14, \n",
    "               'pottedplant': 15, 'sheep': 16, 'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
    "\n",
    "classes = list(classes_num.keys())\n",
    "\n",
    "\n",
    "def voc_load_data(img_dir_path, annotation_path, batch=10):\n",
    "    images, labels = [], []\n",
    "    img_file_list = glob.glob((img_dir_path + \"/*.jpg\"))\n",
    "\n",
    "    for i in range(len(img_file_list)):\n",
    "        for img_path in tqdm.tqdm(img_file_list[batch * i: batch * (i + 1)]):\n",
    "\n",
    "            # Read image\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_h, image_w = image.shape[0:2]\n",
    "\n",
    "            # Resize & normalization\n",
    "            image = cv2.resize(image, (448, 448))\n",
    "            image = image / 255.0\n",
    "\n",
    "            images.append(image)\n",
    "\n",
    "            # Read xml file\n",
    "            xml_name = os.path.split(img_path)[-1]\n",
    "            xml_name = xml_name.split(\".\")[-2]\n",
    "            xml_path = annotation_path + f\"/{xml_name}.xml\"\n",
    "\n",
    "            # parse xml\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Empty matrix\n",
    "            label_matrix = numpy.zeros((7, 7, 25))\n",
    "\n",
    "            for obj in root.iter('object'):\n",
    "                difficult = obj.find('difficult').text\n",
    "                class_name = obj.find('name').text\n",
    "                if class_name not in classes or difficult == \"1\":\n",
    "                    continue\n",
    "\n",
    "                # Set class id\n",
    "                cls_id = classes.index(class_name)\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                tlx, tly = int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text)\n",
    "                brx, bry = int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text)\n",
    "\n",
    "                # point -> 0~1 normalization\n",
    "                x = (tlx + brx) / 2 / image_w\n",
    "                y = (tly + bry) / 2 / image_h\n",
    "                w = (brx - tlx) / image_w\n",
    "                h = (bry - tly) / image_h\n",
    "\n",
    "                # loc in 7x7 grid & point(0~1) in grid cell\n",
    "                loc = [7 * x, 7 * y]\n",
    "                loc_i = int(loc[1])\n",
    "                loc_j = int(loc[0])\n",
    "                y = loc[1] - loc_i\n",
    "                x = loc[0] - loc_j\n",
    "\n",
    "                if label_matrix[loc_i, loc_j, 24] == 0:\n",
    "                    # [<----------20---------->|x|y|w|h|pc]\n",
    "                    label_matrix[loc_i, loc_j, cls_id] = 1\n",
    "                    label_matrix[loc_i, loc_j, 20:24] = [x, y, w, h]\n",
    "                    label_matrix[loc_i, loc_j, 24] = 1  # response\n",
    "\n",
    "            labels.append(label_matrix)\n",
    "\n",
    "        return numpy.array(images), numpy.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943187c",
   "metadata": {},
   "source": [
    "# 학습코드 구현 - Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e35477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy\n",
    "import xml.etree.ElementTree as ET\n",
    "import tqdm\n",
    "\n",
    "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, \n",
    "               'bus': 5, 'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, \n",
    "               'diningtable': 10, 'dog': 11, 'horse': 12, 'motorbike': 13, 'person': 14, \n",
    "               'pottedplant': 15, 'sheep': 16, 'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
    "\n",
    "classes = list(classes_num.keys())\n",
    "\n",
    "\n",
    "def voc_load_data(img_dir_path, annotation_path, batch=10):\n",
    "    images, labels = [], []\n",
    "    img_file_list = glob.glob((img_dir_path + \"/*.jpg\"))\n",
    "\n",
    "    for i in range(len(img_file_list)):\n",
    "        for img_path in tqdm.tqdm(img_file_list[batch * i: batch * (i + 1)]):\n",
    "\n",
    "            # Read image\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_h, image_w = image.shape[0:2]\n",
    "\n",
    "            # Resize & normalization\n",
    "            image = cv2.resize(image, (448, 448))\n",
    "            image = image / 255.0\n",
    "\n",
    "            images.append(image)\n",
    "\n",
    "            # Read xml file\n",
    "            xml_name = os.path.split(img_path)[-1]\n",
    "            xml_name = xml_name.split(\".\")[-2]\n",
    "            xml_path = annotation_path + f\"/{xml_name}.xml\"\n",
    "\n",
    "            # parse xml\n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Empty matrix\n",
    "            label_matrix = numpy.zeros([7, 7, 25])\n",
    "\n",
    "            for obj in root.iter('object'):\n",
    "                difficult = obj.find('difficult').text\n",
    "                class_name = obj.find('name').text\n",
    "                if class_name not in classes or difficult == \"1\":\n",
    "                    continue\n",
    "\n",
    "                # Set class id\n",
    "                cls_id = classes.index(class_name)\n",
    "                xmlbox = obj.find('bndbox')\n",
    "                tlx, tly = int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text)\n",
    "                brx, bry = int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text)\n",
    "\n",
    "                # point -> 0~1 normalization\n",
    "                x = (tlx + brx) / 2 / image_w\n",
    "                y = (tly + bry) / 2 / image_h\n",
    "                w = (brx - tlx) / image_w\n",
    "                h = (bry - tly) / image_h\n",
    "\n",
    "                # loc in 7x7 grid & point(0~1) in grid cell\n",
    "                loc = [7 * x, 7 * y]\n",
    "                loc_i = int(loc[1])\n",
    "                loc_j = int(loc[0])\n",
    "                y = loc[1] - loc_i\n",
    "                x = loc[0] - loc_j\n",
    "\n",
    "                if label_matrix[loc_i, loc_j, 24] == 0:\n",
    "                    # [<----------20---------->|x|y|w|h|pc]\n",
    "                    label_matrix[loc_i, loc_j, cls_id] = 1\n",
    "                    label_matrix[loc_i, loc_j, 20:24] = [x, y, w, h]\n",
    "                    label_matrix[loc_i, loc_j, 24] = 1  # response\n",
    "\n",
    "            labels.append(label_matrix)\n",
    "\n",
    "        return numpy.array(images), numpy.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0a0dd",
   "metadata": {},
   "source": [
    "# 학습코드 구현 - Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197fdd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import math\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import numpy\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, \n",
    "               'bus': 5, 'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, \n",
    "               'diningtable': 10, 'dog': 11, 'horse': 12, 'motorbike': 13, 'person': 14, \n",
    "               'pottedplant': 15, 'sheep': 16, 'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
    "\n",
    "classes = list(classes_num.keys())\n",
    "\n",
    "\n",
    "class SequenceData(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, model, img_dir_path, annotation_path, target_size, batch_size, shuffle=True, use_only=10):\n",
    "        self.model = model\n",
    "        self.datasets = glob.glob((img_dir_path + \"/*.jpg\"))[:use_only]\n",
    "        self.image_path = img_dir_path\n",
    "        self.label_path = annotation_path\n",
    "        self.image_size = target_size[0:2]\n",
    "        # batch_size를 맴버변수에 저장합니다.\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.datasets))\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        num_imgs = len(self.datasets)\n",
    "        # 이미지 개수를 batch 크기로 나눈 값을 \"올림\" 합니다.\n",
    "        return math.ceil(num_imgs / float(self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # batch_size 만큼의 index를 전달 합니다.\n",
    "        # 예) batch_size가 2라면, self.indexes[idx * 2:(idx+1) * 2] 라고 일반화 할 수 있습니다.\n",
    "        # 그러면 idx가 0부터 커짐에 따라 순차적으로 [0:2], [2:4], [4:6] 값을 가져오게 됩니다.\n",
    "        batch_indexs = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch = [self.datasets[k] for k in batch_indexs]\n",
    "        X, y = self.data_generation(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def read(self, image_path):\n",
    "        xml_path = os.path.join(os.path.abspath(self.label_path),\n",
    "                                os.path.split(image_path)[-1].split('.')[0]) + \".xml\"\n",
    "\n",
    "        image = cv.imread(image_path)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image_h, image_w = image.shape[0:2]\n",
    "        image = cv.resize(image, self.image_size)\n",
    "        image = image / 255.\n",
    "\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        label_matrix = numpy.zeros([7, 7, 25])\n",
    "\n",
    "        label_matrix = np.zeros([7, 7, 25])\n",
    "        for obj in root.iter('object'):\n",
    "            difficult = obj.find('difficult').text\n",
    "            class_name = obj.find('name').text\n",
    "            if class_name not in classes or difficult == \"1\":\n",
    "                continue\n",
    "\n",
    "            cls_id = classes.index(class_name)\n",
    "            xmlbox = obj.find('bndbox')\n",
    "            tlx, tly = int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text)\n",
    "            brx, bry = int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text)\n",
    "            x = (tlx + brx) / 2 / image_w\n",
    "            y = (tly + bry) / 2 / image_h\n",
    "            w = (brx - tlx) / image_w\n",
    "            h = (bry - tly) / image_h\n",
    "\n",
    "            loc = [7 * x, 7 * y]\n",
    "            loc_i = int(loc[1])\n",
    "            loc_j = int(loc[0])\n",
    "            y = loc[1] - loc_i\n",
    "            x = loc[0] - loc_j\n",
    "\n",
    "            if label_matrix[loc_i, loc_j, 24] == 0:\n",
    "                label_matrix[loc_i, loc_j, cls_id] = 1\n",
    "                label_matrix[loc_i, loc_j, 20:24] = [x, y, w, h]\n",
    "                label_matrix[loc_i, loc_j, 24] = 1  # response\n",
    "\n",
    "        return image, label_matrix\n",
    "\n",
    "    def data_generation(self, batch_datasets):\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for dataset in batch_datasets:\n",
    "            image, label = self.read(dataset)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "        X = np.array(images)\n",
    "        y = np.array(labels)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460e7f3",
   "metadata": {},
   "source": [
    "# 출력 센서 디코딩1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "\n",
    "def decode(y, image_w, image_h):\n",
    "    boxes = []\n",
    "    \"\"\"\n",
    "    출력 텐서를 해석하여 x, y, w, h로 표현되는 바운딩 박스를 리턴하는 함수를 구현해주세요.\n",
    "    \"\"\"\n",
    "    # image_w, image_h = 448, 448\n",
    "    # 7 x 7의 그리드 셀을 순회하며\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "\n",
    "            grid_vector = y[0]\n",
    "                \n",
    "            # 두 개의 Anchorbox를 찾아냅니다\n",
    "            # AnchorBox는 = [x, y, w, h] 로 구성되어 있습니다.\n",
    "            # 이때 x, y는 셀 안에서의 중심 좌표라는 것을 명심하세요!\n",
    "            anchor_boxA = grid_vector[i, j, 20:25]\n",
    "            anchor_boxB = grid_vector[i, j, 25:]\n",
    "            box1 = anchor_boxA.copy()\n",
    "            box2 = anchor_boxB.copy()\n",
    "                \n",
    "            box1[0] = (j + box1[0]) / 7 * image_w\n",
    "            box1[1] = (i + box1[1]) / 7 * image_h\n",
    "            box1[2] = box1[2] * image_w\n",
    "            box1[3] = box1[3] * image_h\n",
    "\n",
    "\n",
    "            box2[0] = (j + box2[0]) / 7 * image_w\n",
    "            box2[1] = (i + box2[1]) / 7 * image_h\n",
    "            box2[2] = box2[2] * image_w\n",
    "            box2[3] = box2[3] * image_h\n",
    "\n",
    "            # 첫번째 박스의 중심좌표를 tlx, tly로 변환합니다.\n",
    "            box1[0] -= (box1[2] / 2)\n",
    "            box1[1] -= (box1[3] / 2)\n",
    "\n",
    "            # 두번째 박스의 중심좌표를 tlx, tly으로 변환합니다.\n",
    "            box2[0] -= (box2[2] / 2)\n",
    "            box2[1] -= (box2[3] / 2)\n",
    "\n",
    "            boxes.append(box1)\n",
    "            boxes.append(box2)\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5786dc2",
   "metadata": {},
   "source": [
    "# 출력 센서 디코딩2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d7dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "\n",
    "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5,\n",
    "               'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11,\n",
    "               'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16,\n",
    "               'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
    "\n",
    "classes = list(classes_num.keys())\n",
    "\n",
    "\n",
    "\n",
    "def intersection_over_union(box1, box2):\n",
    "\n",
    "    # 교집합 부분의 top left 좌표와 bottom right 좌표를 계산합니다.\n",
    "    x1 = numpy.maximum(box1[0], box2[0])\n",
    "    y1 = numpy.maximum(box1[1], box2[1])\n",
    "    x2 = numpy.minimum(box1[0] + box1[2], box2[0] + box2[2])\n",
    "    y2 = numpy.minimum(box1[1] + box1[3], box2[1] + box2[3])\n",
    "\n",
    "    # 교집합의 넒이를 구합니다.\n",
    "    intersection = numpy.maximum(x2 - x1, 0) * numpy.maximum(y2 - y1, 0)\n",
    "\n",
    "    # 박스1의 넓이와 박스2의 넓이를 각각 구합니다.\n",
    "    box1_area = box1[2] * box1[3]\n",
    "    box2_area = box2[2] * box2[3]\n",
    "\n",
    "    # 두 박스의 넒이를 더한뒤 교집합 영역 넓이를 뺴면 합영역이 됩니다.\n",
    "    union = box1_area + box2_area - intersection\n",
    "\n",
    "    # iou를 계산합니다.\n",
    "    iou = intersection / union\n",
    "    return iou\n",
    "\n",
    "\n",
    "def decode(y, image_shape, class_confidence_threshold=0.4, iou_threshold=0.1):\n",
    "    boxes, names = [], []\n",
    "\n",
    "    grid_vector = y[0]\n",
    "    \n",
    "    # NMS 진행 : IOU가 높아 겹치는 박스를 제거합니다\n",
    "    # 아래 NMS 배열은 98개의 클래스 별 신뢰도를 담을 행렬입니다.\n",
    "    # 0 ~ 20 행까지는 클래스 별 신뢰도를, 20 ~ 25행 까지는 AnchorBox의 좌표와 신뢰도 값을 저장합니다.\n",
    "    # 아래 코드의 빈칸을 채워주세요\n",
    "    nms = numpy.zeros((25, 98))\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            box_num = i * 7 + j\n",
    "            # AnchorBox A\n",
    "            nms[:20, box_num] = grid_vector[i, j, 0:20]\n",
    "            # 박스의 confidence를 클래스 confidence에 곱하여 \n",
    "            # 박스의 위치와 클래스 모두 고려될 수 있도록 합니다.\n",
    "            nms[:20, box_num] *= grid_vector[i, j, 24]\n",
    "            nms[20:, box_num] = grid_vector[i, j, 20:25]\n",
    "                                \n",
    "            # 박스 좌표 변환 : 그리드 셀에서 좌표를 -> x, y, w, h로 image_shape에 맞게\n",
    "            nms[20, box_num] = (j + grid_vector[i, j, 20]) / 7 * image_shape[1]\n",
    "            nms[21, box_num] = (i + grid_vector[i, j, 21]) / 7 * image_shape[0]\n",
    "            nms[22, box_num] = grid_vector[i, j, 22] * image_shape[1]\n",
    "            nms[23, box_num] = grid_vector[i, j, 23] * image_shape[0]\n",
    "                  \n",
    "            # 박스의 중심좌표를 x1, y1으로 변환합니다.\n",
    "            nms[20, box_num] -= (nms[22, box_num] / 2)\n",
    "            nms[21, box_num] -= (nms[23, box_num] / 2)\n",
    "            \n",
    "\n",
    "\n",
    "            # AnchorBox B\n",
    "            nms[:20, box_num + 1] = grid_vector[i, j, 0:20]\n",
    "            # 박스의 confidence를 클래스 confidence에 곱하여 \n",
    "            # 박스의 위치와 클래스 모두 고려될 수 있도록 합니다.\n",
    "            nms[:20, box_num + 1] *= grid_vector[i, j, -1]\n",
    "\n",
    "            nms[20:, box_num + 1] = grid_vector[i, j, 25:]\n",
    "            \n",
    "            # 박스 좌표 변환 : 그리드 셀에서 좌표를 -> x, y, w, h로 image_shape에 맞게\n",
    "            nms[20, box_num + 1] = (j + grid_vector[i, j, 25]) / 7 * image_shape[1]\n",
    "            nms[21, box_num + 1] = (i + grid_vector[i, j, 26]) / 7 * image_shape[0]\n",
    "            nms[22, box_num + 1] = grid_vector[i, j, 27] * image_shape[1]\n",
    "            nms[23, box_num + 1] = grid_vector[i, j, 28] * image_shape[0]\n",
    "                    \n",
    "            # 박스의 중심좌표를 x1, y1으로 변환합니다.\n",
    "            nms[20, box_num + 1] -= (nms[22, box_num + 1] / 2)\n",
    "            nms[21, box_num + 1] -= (nms[23, box_num + 1] / 2)\n",
    "\n",
    "\n",
    "    # 아래 주석을 해제하면, nms 배열에 클래스 별 신뢰도 값이 복사되었는지 알 수 있습니다.\n",
    "    for c in range(20):\n",
    "        for k in range(0, 98):\n",
    "            print(f\"{classes[c]}에 대한 {k} 번째 박스 신뢰도는 {nms[c, k]}\")\n",
    "\n",
    "    # 모든 클래스 마다\n",
    "    for class_id in range(nms.shape[0] - 5):\n",
    "        # 모든 박스별로\n",
    "        for box_order in range(nms.shape[1]):\n",
    "\n",
    "            # 클래스의 신뢰도가 낮으면 주어진 클래스 threshold 보다 낮으면\n",
    "            # 해당 클래스 신뢰도를 0으로 만듭니다.\n",
    "            if nms[class_id, box_order] < class_confidence_threshold:\n",
    "                # 클래스 신뢰도를 0으로 만듭니다\n",
    "                nms[class_id, box_order] = 0\n",
    "\n",
    "        # class confidence값에 따라 소팅하여\n",
    "        # 클래스 별로 해당 클래스에서 IOU가 높은 것을 제거하도록 \n",
    "        # 해당 박스의 클래스에 신뢰도에 0을 줍니다.\n",
    "        candidates = nms[class_id, :].argsort()[::-1]\n",
    "        for i in range(candidates.shape[0]):\n",
    "            for j in range(i + 1, candidates.shape[0]):\n",
    "                box1 = nms[20:24, candidates[i]]\n",
    "                box2 = nms[20:24, candidates[j]]\n",
    "\n",
    "                iou = intersection_over_union(box1, box2)\n",
    "                \n",
    "                if iou > iou_threshold:\n",
    "                    nms[class_id, candidates[j]] = 0\n",
    "\n",
    "\n",
    "                    \n",
    "    # 아래 주석을 해제하면 IOU로 제거된 이후의 \n",
    "    # 신뢰도를 출력합니다.\n",
    "    # for c in range(20):\n",
    "    #     for k in range(0, 98):\n",
    "\n",
    "    #         print(f\"{classes[c]}에 대한 {k} 번째 박스 신뢰도는 {nms[c, k]}\")\n",
    "    \n",
    "    # 이제 남은 박스들 중 점수가 0이상인 박스들만\n",
    "    # 좌표를 x. y, w, h로 변환 합니다.\n",
    "    for box_num in range(nms.shape[1]):\n",
    "        class_id = numpy.argmax(nms[:20, box_num])\n",
    "        confidence = nms[class_id, box_num]\n",
    "                \n",
    "        if confidence > 0:\n",
    "            box = nms[20:24, box_num].copy()\n",
    "            boxes.append(box)\n",
    "            names.append(classes[class_id])\n",
    "    \n",
    "    return boxes, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676f95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
