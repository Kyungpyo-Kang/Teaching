{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1888c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    iris = load_iris()\n",
    "    X = iris.data[:, [2, 3]]\n",
    "    y = iris.target\n",
    "\n",
    "\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "1. 분류를 위한 의사결정 나무 모델을 정의하고\n",
    "\n",
    "   모델 내부의 파라미터들을 정의합니다.\n",
    "   \n",
    "   Step01. 분류를 위한 의사결정 나무 모델을 정의합니다.\n",
    "           random_state는 0으로 설정합니다.\n",
    "   \n",
    "   Step02. param_grid의 criterion, max_depth, \n",
    "           min_samples_split에 원하는 다양한 값을 딕셔너리 형태로 \n",
    "           넣어줍니다. 각 인자의 값은 1차원 리스트여야 합니다.\n",
    "           \n",
    "   Step03. grid_dtree 변수를 GridSearchCV로 정의하고,\n",
    "           GridSearchCV 안에서 refit과 return_train_score은\n",
    "           각각 True로 설정합니다.\n",
    "           \n",
    "   Step04. grid_dtree를 학습시킵니다.\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def DT_clf(train_X, train_y):  \n",
    "    \n",
    "    iris_tree = DecisionTreeClassifier(random_state=0)\n",
    "    \n",
    "    param_grid = {'criterion' : ['entropy', 'gini'], \n",
    "                  'max_depth' : [1,2,3,4,5], \n",
    "                  'min_samples_split' : [2,3]}\n",
    "    \n",
    "    grid_dtree = GridSearchCV(iris_tree, \n",
    "                              param_grid = param_grid,\n",
    "                              refit= True, \n",
    "                              return_train_score = True)\n",
    "                            \n",
    "    grid_dtree.fit(train_X, train_y)\n",
    "                                  \n",
    "    return grid_dtree\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "2. 다양한 인자를 설정한 후 학습시킨 분류 의사결정 \n",
    "   나무 모델들 중, 최고 성능을 가진 모델의\n",
    "\n",
    "   파라미터 목록과 정확도를 살펴봅시다. \n",
    "      \n",
    "   Step01. 이미 구현된 함수를 통해 데이터를 불러옵니다.\n",
    "   \n",
    "   Step02. 구현된 DT_clf 함수의 속성을 사용하여\n",
    "           최적의 파라미터와 최고 정확도를\n",
    "           얻고 출력해봅니다.\n",
    "           \n",
    "   Step03. 구현된 DT_clf 함수의 속성을 사용하여\n",
    "           최적의 파라미터로 학습된 estimator를\n",
    "           얻어봅니다.\n",
    "           \n",
    "   Step04. 최적의 파라미터로 학습된 estimator를\n",
    "           사용하여 테스트 데이터에 대한 분류 결과를\n",
    "           예측합니다.\n",
    "           \n",
    "   Step05. 테스트 데이터에 대한 정확도를 확인해봅시다.\n",
    "           우리의 목표는 적절한 파라미터 조정을 통해 테스트\n",
    "           데이터에 대한 정확도가 0.97이상이 나오도록 하는 것입니다.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = load_data()\n",
    "    \n",
    "    model = DT_clf(train_X, train_y)\n",
    "    \n",
    "    best_p = model.best_params_\n",
    "    best_score = model.best_score_\n",
    "    \n",
    "    print('GridSearchCV 최적 파라미터 : ', best_p)\n",
    "    print('GridSearchCV 최고 정확도 : {0:.4f}'.format(best_score))\n",
    "\n",
    "\n",
    "    estimator = model.best_estimator_\n",
    "\n",
    "\n",
    "    pred_y = estimator.predict(test_X)\n",
    "    \n",
    "    accuracy = accuracy_score(test_y, pred_y)\n",
    "    \n",
    "    print('Accuracy: %.5f' % accuracy)\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e718c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data():\n",
    "    # iris 데이터셋을 불러옵니다.\n",
    "\n",
    "    dataset = load_iris()\n",
    "    \n",
    "    # <ToDo>: feature 데이터를 불러옵니다.\n",
    "    x = dataset.data\n",
    "    # <ToDo>: label 데이터를 불러옵니다.\n",
    "    y = dataset.target\n",
    "    \n",
    "    # <ToDo>: feature 데이터의 변수 이름을 불러옵니다. \n",
    "    feature_name = dataset.feature_names\n",
    "    # <ToDo>: label 데이터의 변수 이름을 불러옵니다.\n",
    "    label_name = dataset.target_names\n",
    "    \n",
    "    # <ToDo>: 불러온 데이터 중 70%는 학습용, 30%는 테스트용으로 활용합니다. \n",
    "    # 이때 random_state는 81로 설정합니다.\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=81)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, feature_name, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a00ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import preprocess\n",
    "import DT\n",
    "import plot_graph\n",
    "\n",
    "def main():\n",
    "    # 데이터를 불러옵니다.\n",
    "\n",
    "    x_train, y_train, x_val, y_val, feature_name, label_name = preprocess.load_data()\n",
    "    \n",
    "    # <ToDo>: DT.py 안의 함수를 사용해, 최고의 성능을 보이는\n",
    "    #         모델을 선정하여 훈련용 데이터로 학습시킵니다.\n",
    "    \n",
    "    clf = DT.select_model(x_train, y_train)\n",
    "    trained_clf = DT.train_model(clf, x_train, y_train)\n",
    "    \n",
    "    # confusion matrix를 출력합니다.\n",
    "    plot_graph.plot_confusion_matrix(trained_clf, x_val, y_val)\n",
    "    \n",
    "    # <ToDo>: DT.py 안의 함수를 사용해, 훈련된 모델의 예측 성능\n",
    "    #         (F1-Score)을 검증용 데이터로 계산하고 출력합니다.\n",
    "    \n",
    "    F1_Score = DT.evaluate_model(trained_clf, x_val, y_val)\n",
    "    print(\"F1 Score: %0.2f\" % (F1_Score))\n",
    "    \n",
    "    # <ToDo>: DT.py 안의 함수를 사용해, 모델 학습 중 독립 변수의\n",
    "    #         중요도를 정의하고, 그래프를 통해 확인합니다.\n",
    "    \n",
    "    importance = DT.var_importance(trained_clf)\n",
    "    plot_graph.importance_barplot(trained_clf, importance)\n",
    "    \n",
    "    # 학습된 모델로부터 의사결정 나무의 분류 경계면과 모델의 구조를 출력합니다.\n",
    "    plot_graph.model_plot(trained_clf, x_train, y_train, feature_name, label_name)\n",
    "    \n",
    "    return F1_Score\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4580ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT.py\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def select_model(feature, label):\n",
    "    \n",
    "    # <ToDo>: 사용할 모델을 지시사항에 따라 지정합니다.\n",
    "    estimator = DecisionTreeClassifier(random_state=81)\n",
    "    \n",
    "    # <ToDo>: estimator의 튜닝을 위한 파라미터를 지시사항에 따라 지정합니다.\n",
    "    param_grid = {'max_depth': [2,3,4,5]}\n",
    "    \n",
    "    # <ToDo>: 최적 파라미터로 다시 estimator를 학습시킬지 말지를 지시사항에 따라 지정합니다.\n",
    "    refit = True\n",
    "    \n",
    "    # <ToDo>: k-fold 교차 검증의 k를 지시사항에 따라 지정합니다. \n",
    "    k = 5\n",
    "    \n",
    "    # <ToDo>: 성능 평가 방법을 지시사항에 따라 지정합니다.\n",
    "    scoring = 'f1_micro'\n",
    "    \n",
    "    # GridSearchCV의 인자들을 채워넣습니다.\n",
    "    selected_model = GridSearchCV(estimator = estimator, \n",
    "                                  param_grid = param_grid,\n",
    "                                  refit = refit, \n",
    "                                  cv = k,\n",
    "                                  scoring = scoring)\n",
    "    \n",
    "    return selected_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, feature, label):\n",
    "    \n",
    "    # <ToDo>: 받아온 모델을 feature, label로 학습시킵니다.\n",
    "    trained_model = model.fit(feature, label)\n",
    "    \n",
    "    # <ToDo>: 학습된 모델들 중 최적의 모델을 찾아냅니다.\n",
    "    best_model = trained_model.best_estimator_\n",
    "\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "def var_importance(best_model):\n",
    "    \n",
    "    # <ToDo>: 학습된 모델들 중 최적의 모델에 사용된 독립변수의 중요도를 리턴합니다.\n",
    "    return best_model.feature_importances_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, feature, label):\n",
    "    \n",
    "    # <ToDo>: 검증용으로 주어진 데이터를 이용해서 모델의 성능을 평가합니다.\n",
    "    f1 = model.score(feature, label)\n",
    "    \n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess.py\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data():\n",
    "    # diabetes 데이터셋을 불러옵니다.\n",
    "\n",
    "    dataset = load_diabetes()\n",
    "    \n",
    "    # <ToDo>: feature 데이터를 불러옵니다.\n",
    "    x = dataset.data\n",
    "    # <ToDo>: label 데이터를 불러옵니다.\n",
    "    y = dataset.target\n",
    "    \n",
    "    # <ToDo>: feature 데이터의 변수 이름을 불러옵니다. \n",
    "    feature_name = dataset.feature_names\n",
    "    \n",
    "    # <ToDo>: 불러온 데이터 중 75%는 학습용, 25%는 테스트용으로 활용합니다. \n",
    "    # 이때 random_state는 81로 설정합니다.\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=81)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, feature_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7690d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  main.py\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import preprocess\n",
    "import DT\n",
    "import plot_graph\n",
    "\n",
    "def main():\n",
    "    # 데이터를 불러옵니다.\n",
    "    x_train, y_train, x_val, y_val, feature_name = preprocess.load_data()\n",
    "\n",
    "    # <ToDo>: DT.py 안의 함수를 사용해, 최고의 성능을 보이는\n",
    "\n",
    "    #         모델을 선정하여 훈련용 데이터로 학습시킵니다.\n",
    "    \n",
    "    clf = DT.select_model(x_train, y_train)\n",
    "    trained_clf = DT.train_model(clf, x_train, y_train)\n",
    "\n",
    "\n",
    "    # <ToDo>: DT.py 안의 함수를 사용해, 훈련된 모델의 예측 성능\n",
    "\n",
    "    #         (MSE)을 검증용 데이터로 계산하고 출력합니다.\n",
    "    \n",
    "    MSE = DT.evaluate_model(trained_clf, x_val, y_val)\n",
    "    print(\"MSE: %0.2f\" % (MSE))\n",
    "\n",
    "\n",
    "    # <ToDo>: DT.py 안의 함수를 사용해, 모델 학습 중 독립 변수의\n",
    "\n",
    "    #         중요도를 정의하고, 그래프를 통해 확인합니다.\n",
    "    \n",
    "    importance = DT.var_importance(trained_clf)\n",
    "    plot_graph.importance_barplot(trained_clf, importance)\n",
    "\n",
    "\n",
    "    # 학습된 모델로부터 의사결정 나무의 분류 경계면과 모델의 구조를 출력합니다.\n",
    "\n",
    "    plot_graph.model_plot(trained_clf, x_train[:,4:], y_train , feature_name[4:])\n",
    "    \n",
    "    return MSE\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c191b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT.py\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def select_model(feature, label):\n",
    "    \n",
    "    # <ToDo>: 사용할 모델을 지시사항에 따라 지정합니다.\n",
    "    estimator = DecisionTreeRegressor(random_state=81)\n",
    "    \n",
    "    # <ToDo>: estimator의 튜닝을 위한 파라미터를 지시사항에 따라 지정합니다.\n",
    "    param_grid = {'max_depth': [2,3,4,5,6,7,8,9,10,11]}\n",
    "    \n",
    "    # <ToDo>: 최적 파라미터로 다시 estimator를 학습시킬지 말지를 지시사항에 따라 지정합니다.\n",
    "    refit = True\n",
    "    \n",
    "    # <ToDo>: k-fold 교차 검증의 k를 지시사항에 따라 지정합니다. \n",
    "    k = 5\n",
    "    \n",
    "    # <ToDo>: 성능 평가 방법을 지시사항에 따라 지정합니다.\n",
    "    scoring = 'neg_mean_squared_error'\n",
    "    \n",
    "    # GridSearchCV의 인자들을 채워넣습니다.\n",
    "    selected_model = GridSearchCV(estimator = estimator, \n",
    "                                  param_grid = param_grid,\n",
    "                                  refit = refit, \n",
    "                                  cv = k,\n",
    "                                  scoring = scoring)\n",
    "    \n",
    "    return selected_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, feature, label):\n",
    "    \n",
    "    # <ToDo>: 받아온 모델을 feature, label로 학습시킵니다.\n",
    "    trained_model = model.fit(feature, label)\n",
    "    \n",
    "    # <ToDo>: 학습된 모델들 중 최적의 모델을 찾아냅니다.\n",
    "    best_model = trained_model.best_estimator_\n",
    "\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "def var_importance(best_model):\n",
    "    \n",
    "    # <ToDo>: 학습된 모델들 중 최적의 모델에 사용된 독립변수의 중요도를 리턴합니다.\n",
    "    return best_model.feature_importances_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, feature, label):\n",
    "    \n",
    "    # <ToDo>: 검증용으로 주어진 데이터를 이용해서 모델의 성능을 평가합니다.\n",
    "    mse = model.score(feature, label)\n",
    "    \n",
    "    return mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
