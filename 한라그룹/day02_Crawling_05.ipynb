{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습5: 네이버 역대 박스오피스 순위, 평점 긁기\n",
    "\n",
    "1.   역대 박스오피스 상위 100개 영화 목록 크롤링 (100개 긁을 때 영화 하나가 이상한데 그거 잘 처리하기)\n",
    "2.   평론가평점, 네티즌평점, 관람객 평점 공감순 상위 50개 댓글 평점 평균 수집\n",
    "3.   평론가평점과 관람객 평점 공감순 상위 50개 댓글 평점 평균이 같은 영화 찾기\n",
    "\n",
    "#### 참고: https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EC%97%AD%EB%8C%80+%EB%B0%95%EC%8A%A4%EC%98%A4%ED%94%BC%EC%8A%A4%EC%88%9C%EC%9C%84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EC%97%AD%EB%8C%80+%EB%B0%95%EC%8A%A4%EC%98%A4%ED%94%BC%EC%8A%A4%EC%88%9C%EC%9C%84'\n",
    "\n",
    "res = req.get(url)\n",
    "soup = bs(res.text, 'html.parser')\n",
    "\n",
    "# 만약 영화 리스트를 긁고싶다면?\n",
    "# 영화 하나를 둘러싸고 있는 html 태그가 있을 것이다.\n",
    "# 그리고 대부분 a라는 영화를 둘러싸고 있는 태그는 b라는 영화를 둘러싸고 있는 태그와 동일하다.\n",
    "# 바로 이 점을 주목하여 html 태그를 찾는다.\n",
    "\n",
    "# 즉, 영화를 둘러싸고 있는, 규칙적인, 반복적으로 나타나는 태그를 찾는 것이다.\n",
    "# 그 결과 _content라는 class를 가진 div 밑에 ul 태그 밑에 li 태그가 영화 정보를 담고 있으며, 규칙적으로 반복된다는 것을 발견했다.\n",
    "movierank_li = soup.select('._content > ul > li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 담아줄 빈 리스트를 선언한다.\n",
    "# 왜 이런 생각을 하게 됐을까?\n",
    "# 이전 실습파일에서 주석으로 언급했듯이...\n",
    "\n",
    "# 크롤링에서 가장 중요한 것은 데이터를 어떻게 구성할 지 미리 그려보는 것이다.\n",
    "# 영화와 관련된 데이터를 긁을테니 컬럼으로 영화제목, 개봉일, url 등등이 들어갈 것이다.\n",
    "\n",
    "# 그러면 무슨 기준으로 컬럼을 선정하는가?\n",
    "# -> 역대박스오피스 순위 페이지에서 규칙적으로 반복되는 영화 정보들을 컬럼으로 선정한다. (ex. 영화제목, 개봉일 등등)\n",
    "\n",
    "movie_title = []\n",
    "movie_date = []\n",
    "movie_ticketsales = []\n",
    "movie_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평점을 긁기 위해서는 영화 상세정보 페이지로 넘어가야 한다.\n",
    "# 예고편을 누르면 영화 상세정보 페이지로 넘어갈 수 있다.\n",
    "# 그런데 왜 다운로드를 눌렀을 때 연결되는 url을 긁으려고 하는 것일까?\n",
    "\n",
    "# 우리가 긁어햐 하는 영화 자료는 크게 두 가지로 나뉜다. \n",
    "# (1) 영화제목, 개봉일, 누적관객수.\n",
    "# (2) 네티즌 평점, 전문가 평점, 공감 순위 등등\n",
    "\n",
    "# 무슨 기준으로 나뉜 것일까?\n",
    "# 웹 페이지 단위이다. 즉, (1)을 긁을 수 있는 웹페이지와 (2)를 긁을 수 있는 웹페이지가 다르다.\n",
    "# 영화 하나에 대한 모든 정보를 긁어오기 위해서 우리는 (1)을 먼저 다 긁고 다른 웹페이지로 접근해서 (2)를 긁어야 한다.\n",
    "# 그리고 (2)를 긁을 수 있는 웹페이지에 대한 url 정보는 (1)에 담겨있다.\n",
    "\n",
    "# 각 영화의 상세정보페이지 url은 뒷부분에 영화코드(mcode)만 다를 뿐 나머지는 동일하다.\n",
    "# 또한, mcode는 다운로드를 눌렀을 때 연결되는 url에 담겨있다.\n",
    "\n",
    "# 따라서, 우리는 영화 상세정보페이지 url에서 변하지 않는 부분은 고정시켜두고\n",
    "# mcode만 바꿔주면서 영화 상세정보를 긁고자 한다.\n",
    "# 그렇기 때문에 다운로드 url을 긁는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'명량'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제목\n",
    "movierank_li[0].select('.movie_tit strong')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 2014.07.30. '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개봉일\n",
    "movierank_li[0].select('.movie_item dd')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17,615,844명'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 관객수\n",
    "movierank_li[0].select('.movie_item dd')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://serieson.naver.com/tvstore/detail.nhn?mcode=93756'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영화코드\n",
    "movierank_li[0].select('.btn_area > a')[0].attrs['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'다운로드'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movierank_li[0].select('.btn_area > a')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 준비가 끝났다.\n",
    "# 이제 매 반복마다 아까 만들어둔 빈 리스트에 데이터를 append해준다.\n",
    "# 그런데 중간에 어떤 영화는 예고편이 없으며, 또 어떤 영화는 다운로드 버튼이 없다.\n",
    "# 이 문제는 if..else..로 처리해주었다.\n",
    "# 어떻게 해결할 지에 대해서는 정답이 있는 것은 아니다. 다양한 방법으로 시도해보자.\n",
    "\n",
    "for movie in movierank_li:\n",
    "    movie_title.append(movie.select('.movie_tit strong')[0].text)\n",
    "    movie_date.append(movie.select('.movie_item dd')[0].text)\n",
    "    movie_ticketsales.append(movie.select('.movie_item dd')[1].text)\n",
    "    \n",
    "    tmp = movie.select('.btn_area > a')\n",
    "    \n",
    "    if len(tmp) == 2:\n",
    "        if tmp[0].text == '다운로드':\n",
    "            movie_url.append(tmp[0].attrs['href'])\n",
    "        else:\n",
    "            movie_url.append(tmp[1].attrs['href'])\n",
    "    else:\n",
    "        if tmp[0].text == '예고편':\n",
    "            movie_url.append(tmp[0].attrs['href'].split('&')[0])\n",
    "        else:\n",
    "            movie_url.append(tmp[0].attrs['href'])\n",
    "\n",
    "movie_dict = {\n",
    "    'movie_title':movie_title,\n",
    "    'movie_date':movie_date,\n",
    "    'movie_ticketsales':movie_ticketsales,\n",
    "    'movie_url' : movie_url\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_date</th>\n",
       "      <th>movie_ticketsales</th>\n",
       "      <th>movie_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>명량</td>\n",
       "      <td>2014.07.30.</td>\n",
       "      <td>17,615,844명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>극한직업</td>\n",
       "      <td>2019.01.23.</td>\n",
       "      <td>16,266,338명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>신과함께-죄와 벌</td>\n",
       "      <td>2017.12.20.</td>\n",
       "      <td>14,414,658명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>국제시장</td>\n",
       "      <td>2014.12.17.</td>\n",
       "      <td>14,264,059명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>어벤져스: 엔드게임</td>\n",
       "      <td>2019.04.24.</td>\n",
       "      <td>13,977,602명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_title     movie_date movie_ticketsales  \\\n",
       "0          명량   2014.07.30.        17,615,844명   \n",
       "1        극한직업   2019.01.23.        16,266,338명   \n",
       "2   신과함께-죄와 벌   2017.12.20.        14,414,658명   \n",
       "3        국제시장   2014.12.17.        14,264,059명   \n",
       "4  어벤져스: 엔드게임   2019.04.24.        13,977,602명   \n",
       "\n",
       "                                           movie_url  \n",
       "0  https://serieson.naver.com/tvstore/detail.nhn?...  \n",
       "1  https://serieson.naver.com/tvstore/detail.nhn?...  \n",
       "2  https://serieson.naver.com/tvstore/detail.nhn?...  \n",
       "3  https://serieson.naver.com/tvstore/detail.nhn?...  \n",
       "4  https://serieson.naver.com/tvstore/detail.nhn?...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) 영화제목, 개봉일, 누적관객수\n",
    "# (1)에 해당하는 정보를 모두 수집했다.\n",
    "# 앞으로 하는 작업은 (2)를 긁기 위해 movie_url에서 mcode를 따로 추출하는 작업이다.\n",
    "# mcode를 추출하는 작업 또한 여러가지 방법이 있을 수 있다.\n",
    "# 다양한 방법으로 시도해보자.\n",
    "\n",
    "tmp_df = pd.DataFrame(movie_dict)\n",
    "tmp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mcode=93756'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df['movie_url'][0].split('?')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df['movie_url'] = tmp_df['movie_url'].apply(lambda x: x.split('?')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code=39569'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df['movie_url'][41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df['movie_code'] = tmp_df['movie_url'].apply(lambda x: x.split('=')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      93756\n",
       "1     167651\n",
       "2      85579\n",
       "3     102875\n",
       "4     136900\n",
       "       ...  \n",
       "95    163533\n",
       "96     52548\n",
       "97    137326\n",
       "98     49727\n",
       "99    144314\n",
       "Name: movie_code, Length: 100, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df['movie_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mcode를 추출했으면 이제 영화상세정보 페이지를 긁을 차례다.\n",
    "# 모든 영화들의 상세정보 페이지 url은 mcode만 다를 뿐 아래 target_url은 똑같다.\n",
    "# 조금 더 구체적으로 말하자면 target_url은 공통사항이며, mcode를 parameter로 받는다. \n",
    "code_list = tmp_df['movie_code']\n",
    "\n",
    "target_url = 'https://movie.naver.com/movie/bi/mi/point.naver?'\n",
    "\n",
    "# 예를 들면, mcode를 담고있는 code_list의 0번째 인덱스에 해당하는 영화의 상세정보 요청 url은 아래와 같다.\n",
    "# 'https://movie.naver.com/movie/bi/mi/point.naver?mcode=xxxx'\n",
    "# params 옵션을 사용해서 요청을 보내자.\n",
    "res = req.get(target_url, params={'code':code_list[0]})\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.29'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래 과정은 코드를 일반화하여 한꺼번에 데이터를 가져오기 전에\n",
    "# 우리에게 필요한 데이터를 어떻게 가져오는지 test해보는 것이다.\n",
    "soup = bs(res.text, 'html.parser')\n",
    "tmp_spc_score = soup.select('.spc_score_area')[0].select('div > em')\n",
    "\n",
    "# tmp_spc_score를 출력해보면 리스트 안에 숫자가 인덱스로 들어가있을 것이다. (['6', '.' , '2', '9'])\n",
    "# 실제 우리에게 필요한 정보는 하나의 소숫점으로 이어진 6.29이다. 따라서 join()함수로 붙여준다.\n",
    "spc_score = ''.join([i.text for i in tmp_spc_score])\n",
    "spc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.44'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네티즌 평점도 어떻게 갖고 오는지 확인해보자.\n",
    "tmp_ntz_score = soup.select('.score_left > .star_score em')\n",
    "ntz_score = ''.join(i.text for i in tmp_ntz_score)\n",
    "ntz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 우리는 관람객 평점을 공감순으로 나열한 후 상위 50개 평균을 구해야 한다.\n",
    "# score_result class에서 ul > li로 평점 정보를 가져올 수 있지만, 또 다른 방법이 있다.\n",
    "\n",
    "# 개발자도구에서 우리가 긁어야할 댓글부분을 확인해보면 아래와 같은 태그를 찾을 수 있다.\n",
    "# <iframe src=\"/movie/bi/mi/pointWriteFormList.naver?code=93756&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false\">\n",
    "# iframe은 웹사이트 안에 있는 자그만한 웹사이트라고 생각하면 편하다.\n",
    "# 관람객 댓글 정보는 사실 하나의 웹사이트로 구성되어있다. 당연히 요청 url도 찾을 수 있다.\n",
    "\n",
    "# iframe src에 들어가서 개발자도구의 네트워크탭을 클릭해보면 요청 url을 얻을 수 있으며, 파라미터에 따라 여러 옵션을 지정해줄 수 있다. \n",
    "# 우리는 나열 순서(order)를 공감순으로 할 것이다. (sympathyScore)\n",
    "\n",
    "# 아래는 iframe의 url로 요청을 보내는 코드이다.\n",
    "target_url2 = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?'\n",
    "\n",
    "param_dict = {\n",
    "    'code':'93756',\n",
    "    'type':'after',\n",
    "    'onlyActualPointYn':'Y',\n",
    "    'onlySpoilerPointYn':'N',\n",
    "    'order':'sympathyScore',\n",
    "    'page':1\n",
    "}\n",
    "\n",
    "res2 = req.get(target_url2, params=param_dict)\n",
    "soup2 = bs(res2.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_act_score = soup2.select('.score_result .star_score em')\n",
    "act_score = list(map(int, [i.text for i in tmp_act_score]))\n",
    "sum(act_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.14"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50개 평균\n",
    "# 한 페이지에 10개의 댓글이 들어있다.\n",
    "# 따라서 우리는 1~5페이지를 긁으면 된다.\n",
    "# 5번을 반복하면서 관람객 평점 50개를 긁고 평균을 구해준다.\n",
    "target_url2 = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?'\n",
    "avg_act_score = 0\n",
    "\n",
    "for i in range(1,5):\n",
    "    \n",
    "    param_dict = {\n",
    "        'code':'93756',\n",
    "        'type':'after',\n",
    "        'onlyActualPointYn':'Y',\n",
    "        'onlySpoilerPointYn':'N',\n",
    "        'order':'sympathyScore',\n",
    "        'page':i\n",
    "    }\n",
    "\n",
    "    res2 = req.get(target_url2, params=param_dict)\n",
    "    soup2 = bs(res2.text, 'html.parser')\n",
    "    tmp_act_score = soup2.select('.score_result .star_score em')\n",
    "    act_score = list(map(int, [i.text for i in tmp_act_score]))\n",
    "    \n",
    "    avg_act_score += sum(act_score)\n",
    "    \n",
    "avg_act_score /= 50\n",
    "avg_act_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 평점 긁기\n",
    "# 아래는 위에서 하나씩 테스트해본 결과를 토대로 영화 100개에 대한 평점 정보를 수집하는 코드이다.\n",
    "# 일반화하여 한번에 모든 영화의 평점 정보를 긁어오는 것이다.\n",
    "target_url = 'https://movie.naver.com/movie/bi/mi/point.naver?'\n",
    "target_url2 = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?'\n",
    "\n",
    "actual_valence = []\n",
    "netizen_valence = []\n",
    "critic_valence = []\n",
    "\n",
    "for movie_code in code_list:\n",
    "    \n",
    "    res = req.get(target_url, params={'code':movie_code})\n",
    "    soup = bs(res.text, 'html.parser')\n",
    "    \n",
    "    # 전문가 평점\n",
    "    try:\n",
    "        tmp_spc_score = soup.select('.spc_score_area')[0].select('div > em')\n",
    "        spc_score = ''.join([i.text for i in tmp_spc_score])\n",
    "        critic_valence.append(float(spc_score))\n",
    "    except:\n",
    "        critic_valence.append(0)\n",
    "    \n",
    "    # 네티즌 평점\n",
    "    try:\n",
    "        tmp_ntz_score = soup.select('.score_left > .star_score em')\n",
    "        ntz_score = ''.join(i.text for i in tmp_ntz_score)\n",
    "        netizen_valence.append(float(ntz_score))\n",
    "    except:\n",
    "        netizen_valence.append(0)\n",
    "    \n",
    "    # 관람객 공감순 50개 평균 평점\n",
    "    avg_act_score = 0\n",
    "\n",
    "    for j in range(1,5):\n",
    "\n",
    "        param_dict = {\n",
    "            'code':movie_code,\n",
    "            'type':'after',\n",
    "            'onlyActualPointYn':'Y',\n",
    "            'onlySpoilerPointYn':'N',\n",
    "            'order':'sympathyScore',\n",
    "            'page':j\n",
    "        }\n",
    "\n",
    "        res2 = req.get(target_url2, params=param_dict)\n",
    "        soup2 = bs(res2.text, 'html.parser')\n",
    "        tmp_act_score = soup2.select('.score_result .star_score em')\n",
    "        act_score = list(map(int, [i.text for i in tmp_act_score]))\n",
    "\n",
    "        avg_act_score += sum(act_score)\n",
    "\n",
    "    avg_act_score /= 50\n",
    "    actual_valence.append(avg_act_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': ['명량',\n",
       "  '극한직업',\n",
       "  '신과함께-죄와 벌',\n",
       "  '국제시장',\n",
       "  '어벤져스: 엔드게임',\n",
       "  '겨울왕국 2',\n",
       "  '베테랑',\n",
       "  '아바타',\n",
       "  '도둑들',\n",
       "  '7번방의 선물',\n",
       "  '알라딘',\n",
       "  '암살',\n",
       "  '범죄도시2',\n",
       "  '광해, 왕이 된 남자',\n",
       "  '신과함께-인과 연',\n",
       "  '택시운전사',\n",
       "  '부산행',\n",
       "  '변호인',\n",
       "  '해운대',\n",
       "  '어벤져스: 인피니티 워',\n",
       "  '실미도',\n",
       "  '괴물',\n",
       "  '왕의 남자',\n",
       "  '어벤져스: 에이지 오브 울트론',\n",
       "  '인터스텔라',\n",
       "  '기생충',\n",
       "  '겨울왕국',\n",
       "  '보헤미안 랩소디',\n",
       "  '검사외전',\n",
       "  '엑시트',\n",
       "  '설국열차',\n",
       "  '관상',\n",
       "  '아이언맨 3',\n",
       "  '캡틴 아메리카: 시빌 워',\n",
       "  '해적: 바다로 간 산적',\n",
       "  '수상한 그녀',\n",
       "  '국가대표',\n",
       "  '백두산',\n",
       "  '과속스캔들',\n",
       "  '탑건: 매버릭',\n",
       "  '스파이더맨: 파 프롬 홈',\n",
       "  '디 워',\n",
       "  '공조',\n",
       "  '트랜스포머 3',\n",
       "  '히말라야',\n",
       "  '스파이더맨: 노 웨이 홈',\n",
       "  '미션 임파서블 : 고스트 프로토콜',\n",
       "  '밀정',\n",
       "  '최종병기 활',\n",
       "  '써니',\n",
       "  '트랜스포머',\n",
       "  '트랜스포머: 패자의 역습',\n",
       "  '스파이더맨: 홈커밍',\n",
       "  '한산: 용의 출현',\n",
       "  '1987',\n",
       "  '베를린',\n",
       "  '마스터',\n",
       "  '터널',\n",
       "  '어벤져스',\n",
       "  '내부자들',\n",
       "  '늑대소년',\n",
       "  '인천상륙작전',\n",
       "  '럭키',\n",
       "  '은밀하게 위대하게',\n",
       "  '범죄도시',\n",
       "  '곡성(哭聲)',\n",
       "  '화려한 휴가',\n",
       "  '좋은 놈, 나쁜 놈, 이상한 놈',\n",
       "  '공조2: 인터내셔날',\n",
       "  '군함도',\n",
       "  '미션 임파서블: 폴아웃',\n",
       "  '웰컴 투 동막골',\n",
       "  '다크 나이트 라이즈',\n",
       "  '사도',\n",
       "  '아저씨',\n",
       "  '킹스맨 : 시크릿 에이전트',\n",
       "  '미션 임파서블: 로그네이션',\n",
       "  '미녀는 괴로워',\n",
       "  '전우치',\n",
       "  '연평해전',\n",
       "  '인셉션',\n",
       "  '레미제라블',\n",
       "  '닥터 스트레인지: 대혼돈의 멀티버스',\n",
       "  '캡틴 마블',\n",
       "  '타짜',\n",
       "  '쥬라기 월드: 폴른 킹덤',\n",
       "  '청년경찰',\n",
       "  '숨바꼭질',\n",
       "  '덕혜옹주',\n",
       "  '더 테러 라이브',\n",
       "  '쥬라기 월드',\n",
       "  '감시자들',\n",
       "  '앤트맨과 와스프',\n",
       "  '닥터 스트레인지',\n",
       "  '검은 사제들',\n",
       "  '안시성',\n",
       "  '의형제',\n",
       "  '블랙 팬서',\n",
       "  '2012',\n",
       "  '더 킹'],\n",
       " 'movie_date': [' 2014.07.30. ',\n",
       "  ' 2019.01.23. ',\n",
       "  ' 2017.12.20. ',\n",
       "  ' 2014.12.17. ',\n",
       "  ' 2019.04.24. ',\n",
       "  ' 2019.11.21. ',\n",
       "  ' 2015.08.05. ',\n",
       "  ' 2009.12.17. ',\n",
       "  ' 2012.07.25. ',\n",
       "  ' 2013.01.23. ',\n",
       "  ' 2019.05.23. ',\n",
       "  ' 2015.07.22. ',\n",
       "  ' 2022.05.18. ',\n",
       "  ' 2012.09.13. ',\n",
       "  ' 2018.08.01. ',\n",
       "  ' 2017.08.02. ',\n",
       "  ' 2016.07.20. ',\n",
       "  ' 2013.12.18. ',\n",
       "  ' 2009.07.22. ',\n",
       "  ' 2018.04.25. ',\n",
       "  ' 2003.12.24. ',\n",
       "  ' 2006.07.27. ',\n",
       "  ' 2005.12.29. ',\n",
       "  ' 2015.04.23. ',\n",
       "  ' 2014.11.06. ',\n",
       "  ' 2019.05.30. ',\n",
       "  ' 2014.01.16. ',\n",
       "  ' 2018.10.31. ',\n",
       "  ' 2016.02.03. ',\n",
       "  ' 2019.07.31. ',\n",
       "  ' 2013.08.01. ',\n",
       "  ' 2013.09.11. ',\n",
       "  ' 2013.04.25. ',\n",
       "  ' 2016.04.27. ',\n",
       "  ' 2014.08.06. ',\n",
       "  ' 2014.01.22. ',\n",
       "  ' 2009.07.29. ',\n",
       "  ' 2019.12.19. ',\n",
       "  ' 2008.12.03. ',\n",
       "  ' 2022.06.22. ',\n",
       "  ' 2019.07.02. ',\n",
       "  ' 2007.08.01. ',\n",
       "  ' 2017.01.18. ',\n",
       "  ' 2011.06.29. ',\n",
       "  ' 2015.12.16. ',\n",
       "  ' 2021.12.15. ',\n",
       "  ' 2011.12.15. ',\n",
       "  ' 2016.09.07. ',\n",
       "  ' 2011.08.10. ',\n",
       "  ' 2011.05.04. ',\n",
       "  ' 2007.06.28. ',\n",
       "  ' 2009.06.24. ',\n",
       "  ' 2017.07.05. ',\n",
       "  ' 2022.07.27. ',\n",
       "  ' 2017.12.27. ',\n",
       "  ' 2013.01.30. ',\n",
       "  ' 2016.12.21. ',\n",
       "  ' 2016.08.10. ',\n",
       "  ' 2012.04.26. ',\n",
       "  ' 2015.11.19. ',\n",
       "  ' 2012.10.31. ',\n",
       "  ' 2016.07.27. ',\n",
       "  ' 2016.10.13. ',\n",
       "  ' 2013.06.05. ',\n",
       "  ' 2017.10.03. ',\n",
       "  ' 2016.05.12. ',\n",
       "  ' 2007.07.25. ',\n",
       "  ' 2008.07.17. ',\n",
       "  ' 2022.09.07. ',\n",
       "  ' 2017.07.26. ',\n",
       "  ' 2018.07.25. ',\n",
       "  ' 2005.08.04. ',\n",
       "  ' 2012.07.19. ',\n",
       "  ' 2015.09.16. ',\n",
       "  ' 2010.08.04. ',\n",
       "  ' 2015.02.11. ',\n",
       "  ' 2015.07.30. ',\n",
       "  ' 2006.12.14. ',\n",
       "  ' 2009.12.23. ',\n",
       "  ' 2015.06.24. ',\n",
       "  ' 2010.07.21. ',\n",
       "  ' 2012.12.19. ',\n",
       "  ' 2022.05.04. ',\n",
       "  ' 2019.03.06. ',\n",
       "  ' 2006.09.28. ',\n",
       "  ' 2018.06.06. ',\n",
       "  ' 2017.08.09. ',\n",
       "  ' 2013.08.14. ',\n",
       "  ' 2016.08.03. ',\n",
       "  ' 2013.07.31. ',\n",
       "  ' 2015.06.11. ',\n",
       "  ' 2013.07.03. ',\n",
       "  ' 2018.07.04. ',\n",
       "  ' 2016.10.26. ',\n",
       "  ' 2015.11.05. ',\n",
       "  ' 2018.09.19. ',\n",
       "  ' 2010.02.04. ',\n",
       "  ' 2018.02.14. ',\n",
       "  ' 2009.11.12. ',\n",
       "  ' 2017.01.18. '],\n",
       " 'movie_ticketsales': ['17,615,844명',\n",
       "  '16,266,338명',\n",
       "  '14,414,658명',\n",
       "  '14,264,059명',\n",
       "  '13,977,602명',\n",
       "  '13,747,792명',\n",
       "  '13,414,484명',\n",
       "  '13,338,865명',\n",
       "  '12,984,701명',\n",
       "  '12,812,144명',\n",
       "  '12,797,929명',\n",
       "  '12,706,855명',\n",
       "  '12,693,195명',\n",
       "  '12,324,062명',\n",
       "  '12,278,010명',\n",
       "  '12,189,698명',\n",
       "  '11,572,066명',\n",
       "  '11,375,223명',\n",
       "  '11,325,117명',\n",
       "  '11,233,176명',\n",
       "  '11,081,000명',\n",
       "  '10,917,400명',\n",
       "  '10,514,177명',\n",
       "  '10,504,007명',\n",
       "  '10,342,523명',\n",
       "  '10,313,345명',\n",
       "  '10,303,058명',\n",
       "  '9,948,386명',\n",
       "  '9,707,119명',\n",
       "  '9,426,421명',\n",
       "  '9,353,799명',\n",
       "  '9,135,806명',\n",
       "  '9,001,679명',\n",
       "  '8,678,117명',\n",
       "  '8,666,208명',\n",
       "  '8,660,760명',\n",
       "  '8,392,617명',\n",
       "  '8,252,909명',\n",
       "  '8,223,342명',\n",
       "  '8,165,687명',\n",
       "  '8,023,606명',\n",
       "  '7,855,474명',\n",
       "  '7,817,686명',\n",
       "  '7,785,189명',\n",
       "  '7,759,711명',\n",
       "  '7,551,990명',\n",
       "  '7,508,976명',\n",
       "  '7,500,457명',\n",
       "  '7,482,180명',\n",
       "  '7,453,733명',\n",
       "  '7,402,732명',\n",
       "  '7,393,443명',\n",
       "  '7,258,678명',\n",
       "  '7,258,076명',\n",
       "  '7,232,452명',\n",
       "  '7,166,688명',\n",
       "  '7,147,924명',\n",
       "  '7,120,780명',\n",
       "  '7,087,068명',\n",
       "  '7,073,581명',\n",
       "  '7,069,579명',\n",
       "  '7,051,237명',\n",
       "  '6,975,631명',\n",
       "  '6,959,083명',\n",
       "  '6,880,546명',\n",
       "  '6,879,989명',\n",
       "  '6,855,433명',\n",
       "  '6,686,075명',\n",
       "  '6,624,892명',\n",
       "  '6,592,168명',\n",
       "  '6,584,919명',\n",
       "  '6,436,900명',\n",
       "  '6,428,574명',\n",
       "  '6,247,745명',\n",
       "  '6,179,525명',\n",
       "  '6,129,651명',\n",
       "  '6,126,488명',\n",
       "  '6,081,480명',\n",
       "  '6,065,474명',\n",
       "  '6,045,353명',\n",
       "  '5,998,647명',\n",
       "  '5,938,797명',\n",
       "  '5,884,595명',\n",
       "  '5,802,811명',\n",
       "  '5,692,997명',\n",
       "  '5,661,231명',\n",
       "  '5,653,444명',\n",
       "  '5,604,106명',\n",
       "  '5,599,995명',\n",
       "  '5,584,295명',\n",
       "  '5,547,463명',\n",
       "  '5,509,019명',\n",
       "  '5,448,134명',\n",
       "  '5,447,269명',\n",
       "  '5,443,232명',\n",
       "  '5,441,020명',\n",
       "  '5,416,923명',\n",
       "  '5,399,327명',\n",
       "  '5,397,597명',\n",
       "  '5,318,007명'],\n",
       " 'movie_url': ['https://serieson.naver.com/tvstore/detail.nhn?mcode=93756',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=167651',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=85579',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=102875',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=136900',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=136873',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=115977',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=62266',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=78726',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=94775',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=163788',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=121048',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=192608',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=83893',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=167697',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=146469',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=130966',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=101901',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=45321',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=136315',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=34501',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=39841',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=39894',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=98438',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=45290',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=161967',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=100931',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=156464',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=130903',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=174903',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=62328',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=93728',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=70254',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=122527',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=102817',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=107924',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=47385',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=187940',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=51143',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=81888',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=173123',\n",
       "  'https://movie.naver.com/movie/bi/mi/mediaView.nhn?code=39569',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=142384',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=70241',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=100647',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=208077',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=53372',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=137952',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=83084',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=76016',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=61521',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=68052',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=135874',\n",
       "  'https://movie.naver.com/movie/bi/mi/mediaView.nhn?code=194196&mid=52832',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=158191',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=89218',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=145162',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=141104',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=72363',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=121788',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=88253',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=142822',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=140695',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=92575',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=161242',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=121051',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=58018',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=65674',\n",
       "  'https://movie.naver.com/movie/bi/mi/mediaView.nhn?code=201641&mid=52998',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=146506',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=154222',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=39405',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=72054',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=121922',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=71509',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=114249',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=95541',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=39157',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=48227',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=102272',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=52515',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=89755',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=182016',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=132623',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=57723',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=154285',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=153652',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=102824',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=94767',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=99794',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=67786',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=98146',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=144330',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=125459',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=120157',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=163533',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=52548',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=137326',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=49727',\n",
       "  'https://serieson.naver.com/tvstore/detail.nhn?mcode=144314']}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새롭게 수집한 평점 정보도 기존 딕셔너리에 추가해준다.\n",
    "movie_dict['critic_valence'] = critic_valence\n",
    "movie_dict['netizen_valence'] = netizen_valence\n",
    "movie_dict['actual_valence'] = actual_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_date</th>\n",
       "      <th>movie_ticketsales</th>\n",
       "      <th>movie_url</th>\n",
       "      <th>critic_valence</th>\n",
       "      <th>netizen_valence</th>\n",
       "      <th>actual_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>명량</td>\n",
       "      <td>2014.07.30.</td>\n",
       "      <td>17,615,844명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "      <td>6.29</td>\n",
       "      <td>8.44</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>극한직업</td>\n",
       "      <td>2019.01.23.</td>\n",
       "      <td>16,266,338명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "      <td>6.80</td>\n",
       "      <td>8.51</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>신과함께-죄와 벌</td>\n",
       "      <td>2017.12.20.</td>\n",
       "      <td>14,414,658명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "      <td>5.92</td>\n",
       "      <td>7.83</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>국제시장</td>\n",
       "      <td>2014.12.17.</td>\n",
       "      <td>14,264,059명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "      <td>5.81</td>\n",
       "      <td>9.02</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>어벤져스: 엔드게임</td>\n",
       "      <td>2019.04.24.</td>\n",
       "      <td>13,977,602명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "      <td>7.62</td>\n",
       "      <td>9.38</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_title     movie_date movie_ticketsales  \\\n",
       "0          명량   2014.07.30.        17,615,844명   \n",
       "1        극한직업   2019.01.23.        16,266,338명   \n",
       "2   신과함께-죄와 벌   2017.12.20.        14,414,658명   \n",
       "3        국제시장   2014.12.17.        14,264,059명   \n",
       "4  어벤져스: 엔드게임   2019.04.24.        13,977,602명   \n",
       "\n",
       "                                           movie_url  critic_valence  \\\n",
       "0  https://serieson.naver.com/tvstore/detail.nhn?...            6.29   \n",
       "1  https://serieson.naver.com/tvstore/detail.nhn?...            6.80   \n",
       "2  https://serieson.naver.com/tvstore/detail.nhn?...            5.92   \n",
       "3  https://serieson.naver.com/tvstore/detail.nhn?...            5.81   \n",
       "4  https://serieson.naver.com/tvstore/detail.nhn?...            7.62   \n",
       "\n",
       "   netizen_valence  actual_valence  \n",
       "0             8.44            7.14  \n",
       "1             8.51            7.30  \n",
       "2             7.83            4.28  \n",
       "3             9.02            7.72  \n",
       "4             9.38            7.92  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(movie_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['critic_actual_diff'] = abs(df['actual_valence'] - df['critic_valence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_date</th>\n",
       "      <th>movie_ticketsales</th>\n",
       "      <th>movie_url</th>\n",
       "      <th>critic_valence</th>\n",
       "      <th>netizen_valence</th>\n",
       "      <th>actual_valence</th>\n",
       "      <th>critic_netizen_diff</th>\n",
       "      <th>critic_actual_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>미션 임파서블: 로그네이션</td>\n",
       "      <td>2015.07.30.</td>\n",
       "      <td>6,126,488명</td>\n",
       "      <td>https://serieson.naver.com/tvstore/detail.nhn?...</td>\n",
       "      <td>7.54</td>\n",
       "      <td>8.75</td>\n",
       "      <td>7.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     movie_title     movie_date movie_ticketsales  \\\n",
       "3     76  미션 임파서블: 로그네이션   2015.07.30.         6,126,488명   \n",
       "\n",
       "                                           movie_url  critic_valence  \\\n",
       "3  https://serieson.naver.com/tvstore/detail.nhn?...            7.54   \n",
       "\n",
       "   netizen_valence  actual_valence  critic_netizen_diff  critic_actual_diff  \n",
       "3             8.75            7.54                  0.0                 0.0  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# '미션 임파서블: 로그네이션'이 평론가 평점과 관람객 공감순 상위 50개 평점 평균이 같은 영화로 나왔다.\n",
    "# 만약 결과가 다르다면 iframe의 요청 url 파라미터를 확인해보자.\n",
    "df = df.sort_values('critic_actual_diff')\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.loc[(df['critic_valence'] != 0) & (df['actual_valence'] != 0) & (df['critic_actual_diff']==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수고하셨습니다!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
