{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d728b508",
   "metadata": {},
   "source": [
    "# [실습6] AI 기법 성능 향상 방법론 (정답)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930bc416",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b38471a",
   "metadata": {},
   "source": [
    "## 실습 목표\n",
    "---\n",
    "- 하이퍼 매개변수 튜닝에 대해 배워봅니다.\n",
    "- K-fold 교차 검증을 수행해봅니다.\n",
    "- Residual network를 구현해봅니다.\n",
    "- Positional encoding을 구현해봅니다.\n",
    "- 금속분말 데이터셋에 대한 최적의 인공지능 모델을 구현해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aedf33",
   "metadata": {},
   "source": [
    "## 실습 목차\n",
    "---\n",
    "1. **Hyper-parameter 튜닝:** 하이퍼 매개변수 튜닝을 수행해봅니다.\n",
    "\n",
    "2. **K-fold 교차검증:** K-fold 교차검증으로 모델을 평가해봅니다.\n",
    "\n",
    "3. **Residual network:** Residual network를 구현해봅니다.\n",
    "\n",
    "4. **Positional encoding:** Positional encoding을 구현해봅니다.\n",
    "\n",
    "5. **최적의 모델 구현:** 여태까지 배웠던 것들을 종합하여 최적의 인공지능 모델을 만들어봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8d71f",
   "metadata": {},
   "source": [
    "## 실습 개요\n",
    "---\n",
    "\n",
    "이번 실습에서는 AI 모델의 성능 향상을 위한 다양한 기법을 수행해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5791f7b",
   "metadata": {},
   "source": [
    "## 1. Hyper-parameter 튜닝\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 하이퍼 매개변수 튜닝을 수행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc64b3",
   "metadata": {},
   "source": [
    "### 1.1 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e951ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "import json\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904ed83",
   "metadata": {},
   "source": [
    "### 1.2 데이터셋 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = {\n",
    "    'train_X': np.load('./Data/train_data_stage1_X.npy'),\n",
    "    'train_y': np.load('./Data/train_data_stage1_y.npy'),\n",
    "    'valid_X': np.load('./Data/valid_data_stage1_X.npy'),\n",
    "    'valid_y': np.load('./Data/valid_data_stage1_y.npy'),\n",
    "    'test_X': np.load('./Data/test_data_stage1_X.npy'),\n",
    "    'test_y': np.load('./Data/test_data_stage1_y.npy'),\n",
    "}\n",
    "\n",
    "stage2 = {\n",
    "    'train_X': np.load('./Data/train_data_stage2_X.npy'),\n",
    "    'train_y': np.load('./Data/train_data_stage2_y.npy'),\n",
    "    'valid_X': np.load('./Data/valid_data_stage2_X.npy'),\n",
    "    'valid_y': np.load('./Data/valid_data_stage2_y.npy'),\n",
    "    'test_X': np.load('./Data/test_data_stage2_X.npy'),\n",
    "    'test_y': np.load('./Data/test_data_stage2_y.npy'),\n",
    "}\n",
    "\n",
    "# 삭제\n",
    "# columns = json.load(open('./Data/valid_columns.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694374d4",
   "metadata": {},
   "source": [
    "### 1.3 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c463f",
   "metadata": {},
   "source": [
    "### 1.3.1 Stage1 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed86735",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_X_mean = stage1['train_X'].mean(axis = 0)\n",
    "stage1_y_mean = stage1['train_y'].mean(axis = 0)\n",
    "print('입력값 평균:', stage1_X_mean)\n",
    "print('출력값 평균:', stage1_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8823e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_X_std = stage1['train_X'].std(axis = 0)\n",
    "stage1_y_std = stage1['train_y'].std(axis = 0)\n",
    "print('입력값 표준편차:', stage1_X_std)\n",
    "print('출력값 표준편차:', stage1_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 표준화\n",
    "stage1['train_X'] = (stage1['train_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['train_y'] = (stage1['train_y'] - stage1_y_mean) / stage1_y_std\n",
    "# 검증용 데이터 표준화\n",
    "stage1['valid_X'] = (stage1['valid_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['valid_y'] = (stage1['valid_y'] - stage1_y_mean) / stage1_y_std\n",
    "# 테스트 데이터 표준화\n",
    "stage1['test_X'] = (stage1['test_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['test_y'] = (stage1['test_y'] - stage1_y_mean) / stage1_y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1040b54",
   "metadata": {},
   "source": [
    "### 1.3.2 Stage2 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_X_mean = stage2['train_X'].mean(axis = 0)\n",
    "stage2_y_mean = stage2['train_y'].mean(axis = 0)\n",
    "print('입력값 평균:', stage2_X_mean)\n",
    "print('출력값 평균:', stage2_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886998c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_X_std = stage2['train_X'].std(axis = 0)\n",
    "stage2_y_std = stage2['train_y'].std(axis = 0)\n",
    "print('입력값 표준편차:', stage2_X_std)\n",
    "print('출력값 표준편차:', stage2_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 표준화\n",
    "stage2['train_X'] = (stage2['train_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['train_y'] = (stage2['train_y'] - stage2_y_mean) / stage2_y_std\n",
    "\n",
    "# 검증용 데이터 표준화\n",
    "stage2['valid_X'] = (stage2['valid_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['valid_y'] = (stage2['valid_y'] - stage2_y_mean) / stage2_y_std\n",
    "\n",
    "# 테스트 데이터 표준화\n",
    "stage2['test_X'] = (stage2['test_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['test_y'] = (stage2['test_y'] - stage2_y_mean) / stage2_y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9857dff",
   "metadata": {},
   "source": [
    "### 1.4 Hyper-parameter 범위 설정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510e00a",
   "metadata": {},
   "source": [
    "랜덤 서치를 이용한 하이퍼파라미터 설정을 해봅니다. 이때 실습 시간을 고려하여, 학습데이터 중 1000개만 사용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.005, 0.03]\n",
    "dropout_rate = [0.0, 0.2]\n",
    "trials = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤한 하이퍼파라미터를 리턴하는 함수\n",
    "def sampling(parameter_range):\n",
    "    min_value, max_value = parameter_range\n",
    "    random_value = np.random.random()\n",
    "    return random_value * (max_value - min_value) + min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "drs = []\n",
    "r2s = []\n",
    "\n",
    "# 총 10회 반복\n",
    "# 매 반복마다 seed 를 다르게 설정 -> 매 반복마다 random한 값들로 구성됨\n",
    "for try_ in range(trials):\n",
    "    np.random.seed(try_)\n",
    "    \n",
    "    # 0.005부터 0.03의 범위에서 랜덤한 값이 도출됨\n",
    "    lr = sampling(learning_rate)\n",
    "    \n",
    "    # 0.0부터 0.2의 범위에서 랜덤한 값이 도출됨\n",
    "    dr = sampling(dropout_rate)\n",
    "    print('%d 번째 시도 - 학습률: %.3f, dropout rate: %.3f'%(try_ + 1, lr, dr))\n",
    "    \n",
    "    # 모델 정의\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    MLP_model = tf.keras.Sequential([\n",
    "        Input(shape = stage1['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate=dr), \n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate=dr), \n",
    "        tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "    ])\n",
    "    # 모델 컴파일\n",
    "    MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(learning_rate = lr),\n",
    "    )\n",
    "    # 모델 학습\n",
    "    history = MLP_model.fit(stage1['train_X'], stage1['train_y'], epochs = 50, batch_size = 16, verbose = 0)\n",
    "    # 모델 예측\n",
    "    pred = MLP_model.predict(stage1['test_X'])\n",
    "    # 모델 평가\n",
    "    r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "    print(\"    -> R2 score: %f\"%r2)\n",
    "    \n",
    "    # 빈 리스트에 매 반복마다 학습률, dropout rate, r-score 추가\n",
    "    # 마지막에 시각화하기 위함\n",
    "    lrs.append(lr)\n",
    "    drs.append(dr)\n",
    "    r2s.append(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lrs, r2s)\n",
    "plt.xlabel('learning rate')\n",
    "plt.ylabel('r2 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(drs, r2s)\n",
    "plt.xlabel('dropout rate')\n",
    "plt.ylabel('r2 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26534d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(lrs, r2s)[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(drs, r2s)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451371c",
   "metadata": {},
   "source": [
    "학습률은 모델의 성능과 상관 관계가 큰 반면, dropout rate는 비교적 상관 관계가 약한 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0d2a7",
   "metadata": {},
   "source": [
    "**[TODO] Stage 2 데이터에 대해 hyper-parameter 튜닝을 수행해보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "drs = []\n",
    "r2s = []\n",
    "for try_ in range(trials):\n",
    "    np.random.seed(try_)\n",
    "    lr = sampling(learning_rate)\n",
    "    dr = sampling(dropout_rate)\n",
    "    print('%d 번째 시도 - 학습률: %.3f, dropout rate: %.3f'%(try_ + 1, lr, dr))\n",
    "    \n",
    "    # 모델 정의\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    MLP_model = tf.keras.Sequential([\n",
    "        Input(shape = stage2['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate=dr), \n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(rate=dr), \n",
    "        tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "    ])\n",
    "    # 모델 컴파일\n",
    "    MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(learning_rate = lr),\n",
    "    )\n",
    "    # 모델 학습\n",
    "    history = MLP_model.fit(stage2['train_X'], stage2['train_y'], epochs = 50, batch_size = 16, verbose = 0)\n",
    "    # 모델 예측\n",
    "    pred = MLP_model.predict(stage2['test_X'])\n",
    "    # 모델 평가\n",
    "    r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "    print(\"    -> R2 score: %f\"%r2)\n",
    "    lrs.append(lr)\n",
    "    drs.append(dr)\n",
    "    r2s.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(lrs, r2s)[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e9c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.corrcoef(drs, r2s)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccff72f",
   "metadata": {},
   "source": [
    "## 2. K-fold 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eeb3b0",
   "metadata": {},
   "source": [
    "### 2.1 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8956ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stage1 = np.concatenate([stage1['train_X'], stage1['valid_X']])\n",
    "y_stage1 = np.concatenate([stage1['train_y'], stage1['valid_y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복1\n",
    "# training idxs\n",
    "# 0 ~ 1/5까지\n",
    "# 2/5 ~ 끝까지\n",
    "\n",
    "# valid idxs\n",
    "# 1/5 ~ 2/5 Rkwl\n",
    "\n",
    "# 반복2\n",
    "# training idxs\n",
    "# 0 ~ 2/5까지\n",
    "# 3/5 ~ 끝까지\n",
    "\n",
    "# valid idxs\n",
    "# 2/5 ~ 3/5까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b39202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold 데이터셋을 도출하는 함수\n",
    "# 매개변수로 독립변수, 종속변수, fold 개수를 받음\n",
    "# k-1개: training, 1개: validation\n",
    "def get_K_fold_dataset(X, y, K):\n",
    "    dataset = {}\n",
    "    len_data = len(X)\n",
    "    idxs = np.arange(len_data)\n",
    "    \n",
    "    # k번 반복수행\n",
    "    for k in range(K):\n",
    "        # training: 데이터 길이의 1/5부터 2/5, 2/5부터 \n",
    "        training_idxs = np.concatenate([idxs[:int(len_data * k/K)], idxs[int(len_data * (k+1)/K):]])\n",
    "        valid_idxs = idxs[int(len_data * k/K) : int(len_data * (k+1)/K)]\n",
    "        dataset['%d-fold'%(k+1)] = {\n",
    "            'train_X': X[training_idxs],\n",
    "            'valid_X': X[valid_idxs],\n",
    "            'train_y': y[training_idxs],\n",
    "            'valid_y': y[valid_idxs]\n",
    "        }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd40cda",
   "metadata": {},
   "source": [
    "데이터를 K 개의 학습-테스트 셋으로 분리하는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 fold\n",
    "# K_fold는 dictionary 안에 dictionary 형태의 데이터셋\n",
    "# 총 5개의 key: '1-fold', '2-fold', '3-fold', '4-fold', '5-fold' 가 있음.\n",
    "# 각각의 key에 대한 value에는 train_X, valid_X, train_y, valid_y라는 또다른 key값이 있음\n",
    "K_fold = get_K_fold_dataset(X_stage1, y_stage1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2s = []\n",
    "# 매 반복마다 K에는 각각\n",
    "# train_X, valid_X, train_y, valid_y 이 들어감\n",
    "for K in K_fold.keys():\n",
    "    # 첫번째 반복이라 가정 -> 이때 K는 1-fold\n",
    "    # 따라서 데이터셋은 1-fold 에 해당하는 train_X, valid_X, train_y, valid_y\n",
    "    dataset = K_fold[K]\n",
    "    print('%s'%K)\n",
    "    # 모델 정의\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    MLP_model = tf.keras.Sequential([\n",
    "        Input(shape = stage1['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "    ])\n",
    "    # 모델 컴파일\n",
    "    MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "    )\n",
    "    # 모델 학습\n",
    "    history = MLP_model.fit(dataset['train_X'], dataset['train_y'], epochs = 50, batch_size = 16, verbose = 0)\n",
    "    # 모델 예측\n",
    "    pred = MLP_model.predict(dataset['valid_X'])\n",
    "    # 모델 평가\n",
    "    r2 = sklearn.metrics.r2_score(dataset['valid_y'], pred)\n",
    "    print(\"    -> R2 score: %f\"%r2)\n",
    "    r2s.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcf80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K개 fold에서 나온 성능의 평균\n",
    "Average_r2 = np.mean(r2s)\n",
    "print(\"Average R2 score: %f\"%Average_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ccb778",
   "metadata": {},
   "source": [
    "모델의 최종 성능을 평가할 때에는, K개의 fold에서 나온 성능의 평균을 취합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd4e33",
   "metadata": {},
   "source": [
    "**[TODO] Stage2 데이터에 대해 K-fold 교차검증을 수행해보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stage2 = np.concatenate([stage2['train_X'], stage2['valid_X']])\n",
    "y_stage2 = np.concatenate([stage2['train_y'], stage2['valid_y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14928130",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_fold = get_K_fold_dataset(X_stage2, y_stage2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6459082",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2s = []\n",
    "for K in K_fold.keys():\n",
    "    dataset = K_fold[K]\n",
    "    print('%s'%K)\n",
    "    # 모델 정의\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    MLP_model = tf.keras.Sequential([\n",
    "        Input(shape = stage2['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "    ])\n",
    "    # 모델 컴파일\n",
    "    MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "    )\n",
    "    # 모델 학습\n",
    "    history = MLP_model.fit(dataset['train_X'], dataset['train_y'], epochs = 50, batch_size = 16, verbose = 0)\n",
    "    # 모델 예측\n",
    "    pred = MLP_model.predict(dataset['valid_X'])\n",
    "    # 모델 평가\n",
    "    r2 = sklearn.metrics.r2_score(dataset['valid_y'], pred)\n",
    "    print(\"    -> R2 score: %f\"%r2)\n",
    "    r2s.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76767141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Average_r2 = np.mean(r2s)\n",
    "print(\"Average R2 score: %f\"%Average_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101bb67",
   "metadata": {},
   "source": [
    "## 3. Residual network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f48b4",
   "metadata": {},
   "source": [
    "### 3.1 Residual network 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.Model 이라는 부모클래스에서 상속받아서 새로운 클래스 정의\n",
    "# 상속을 받으면 tf.keras.Model 이 갖고 있는 모든 특성 (메소드, 멤버변수 등) 가져다가 사용할 수 있음\n",
    "# 붕어빵 틀\n",
    "\n",
    "# 클래스와 객체\n",
    "# 클래스가 붕어빵 틀이라면 객체는 붕어빵\n",
    "# 생성자는 슈크림 붕어빵인지 팥 붕어빵인지 초기에 세팅해주는 것\n",
    "\n",
    "class ResidualMLP(tf.keras.Model):\n",
    "    # 생성자\n",
    "    # self는 객체의 주소값을 받아옴 -> 내가 빵틀에서 빵을 찍어낼건데, 너는 어떤 빵이니?\n",
    "    # out_dim, use_residual을 생성자로 받아옴\n",
    "    \n",
    "    def __init__(self, out_dim, use_residual):\n",
    "        # 부모클래스의 생성자를 그대로 가져옴 -> Model이 가지고 있는 모든 함수 이용 가능\n",
    "        super(ResidualMLP, self).__init__()\n",
    "        self.use_residual = use_residual\n",
    "        # 총 8개의 fully connected layer\n",
    "        self.fc1 = tf.keras.layers.Dense(16, activation = 'relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(16, activation = 'relu')\n",
    "        self.fc3 = tf.keras.layers.Dense(16, activation = 'relu')\n",
    "        self.fc4 = tf.keras.layers.Dense(16, activation = 'relu')\n",
    "        self.fc5 = tf.keras.layers.Dense(16, activation = 'relu')\n",
    "        self.fc6 = tf.keras.layers.Dense(16, activation = 'relu')\n",
    "        self.fc7 = tf.keras.layers.Dense(16, activation = 'relu')\n",
    "        self.fc8 = tf.keras.layers.Dense(16, activation = 'relu')\n",
    "        self.fc9 = tf.keras.layers.Dense(out_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        # 객체의 use_residual이 True라면 실행\n",
    "        if self.use_residual:\n",
    "            h = self.fc1(x)\n",
    "            h = self.fc2(h) + h\n",
    "            h = self.fc3(h) + h\n",
    "            h = self.fc4(h) + h\n",
    "            h = self.fc5(h) + h\n",
    "            h = self.fc6(h) + h\n",
    "            h = self.fc7(h) + h\n",
    "            h = self.fc8(h) + h\n",
    "            h = self.fc9(h)\n",
    "        else:\n",
    "            h = self.fc1(x)\n",
    "            h = self.fc2(h)\n",
    "            h = self.fc3(h)\n",
    "            h = self.fc4(h)\n",
    "            h = self.fc5(h)\n",
    "            h = self.fc6(h)\n",
    "            h = self.fc7(h)\n",
    "            h = self.fc8(h)\n",
    "            h = self.fc9(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e487f29",
   "metadata": {},
   "source": [
    "Resiudal network 같이 복잡한 네트워크를 정의하기 위해서는 Sequential 보다 위 처럼 직접 class 를 정의하는 것이 편리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# 객체 생성 (use_residual 은 True)\n",
    "MLP_model_residual = ResidualMLP(stage1['train_y'].shape[1], use_residual = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3be61",
   "metadata": {},
   "source": [
    "### 3.2 Residual network 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model_residual.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c16f3",
   "metadata": {},
   "source": [
    "### 3.3 Residual network 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d362a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model_residual.fit(stage1['train_X'], stage1['train_y'], epochs = 500, batch_size = 16, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9096dd",
   "metadata": {},
   "source": [
    "### 3.4 Residual network 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_residual.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe86389",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de1dc7c",
   "metadata": {},
   "source": [
    "### 3.5 일반 MLP 와의 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# 객체 생성 (use_residual 은 False)\n",
    "MLP_model = ResidualMLP(stage1['train_y'].shape[1], use_residual = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080b771b",
   "metadata": {},
   "source": [
    "use_residual 을 False로 설정하여 일반 MLP 네트워크를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113876f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0324a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "history = MLP_model.fit(stage1['train_X'], stage1['train_y'], epochs = 50, batch_size = 16, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba203f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측\n",
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c8a648",
   "metadata": {},
   "source": [
    "Residual network 가 더 성능이 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df8be3",
   "metadata": {},
   "source": [
    "**[TODO] Stage2 데이터에 대해 Residual network 를 학습해보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resiudal network 모델 정의\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model_residual = ResidualMLP(stage2['train_y'].shape[1], use_residual = True)\n",
    "\n",
    "# resiudal network 사용하지 않는 모델 정의\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model = ResidualMLP(stage2['train_y'].shape[1], use_residual = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed113dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "\n",
    "MLP_model_residual.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e789991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# residual 모델 학습\n",
    "MLP_model_residual.fit(stage2['train_X'], stage2['train_y'], epochs = 50, batch_size = 16, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808f782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 일반 MLP 모델 학습\n",
    "MLP_model.fit(stage2['train_X'], stage2['train_y'], epochs = 50, batch_size = 16, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual 모델 예측\n",
    "pred = MLP_model_residual.predict(stage2['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual 모델 평가\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 MLP 모델 예측\n",
    "pred = MLP_model.predict(stage2['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88c8bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 일반 MLP 모델 평가\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee383e",
   "metadata": {},
   "source": [
    "## 4. Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcdb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L은 위치 인코딩에서 사용되는 주파수(frequency)의 개수를 의미.\n",
    "# frequency는 주파수를 의미\n",
    "# 위치 인코딩은 사인(sin)과 코사인(cos) 함수를 사용하여 위치 정보를 인코딩\n",
    "# 이 때 주파수가 높을수록 더 빠른 주기로 변화\n",
    "# 주파수는 주기를 반복하는 빈도를 나타내는데, 예를 들어 주파수가 높을수록 더 자주 반복되는 주기가 발생\n",
    "# 따라서 L 값이 클수록 주파수가 높아지며, 더 많은 주기가 포함된 위치 인코딩 값을 생성\n",
    "# 이로 인해 더 많은 세부적인 위치 정보가 인코딩되어 모델이 입력 시퀀스의 순서를 더 세밀하게 학습\n",
    "\n",
    "# X: 입력 시퀀스의 위치 정보를 나타내는 배열. 크기는 (N, d)이며, N은 시퀀스의 길이이고, d는 입력 벡터의 차원\n",
    "# L: 위치 인코딩의 차원을 결정하는 파라미터로, 정수\n",
    "def positional_encoding(X, L):\n",
    "    Xs = []\n",
    "    # l이 증가할수록 사인과 코사인 함수의 주기가 더 빠르게 변하므로, 더 높은 주파수 정보를 포함합니다.\n",
    "    for l in range(L):\n",
    "        # sin, cos의 인자값은 radian이기 때문에 pi를 곱해줌\n",
    "        Xs.append(np.sin(2 ** l * np.pi * X))\n",
    "        Xs.append(np.cos(2 ** l * np.pi * X))        \n",
    "    return np.concatenate(Xs, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc86c72f",
   "metadata": {},
   "source": [
    "입력 데이터를 L개의 frequency를 가진 데이터로 변환하는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf511f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = positional_encoding(stage1['train_X'], 5)\n",
    "test_X = positional_encoding(stage1['test_X'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model_pe = ResidualMLP(stage1['train_y'].shape[1], use_residual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19787138",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model_pe.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df11f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model_pe.fit(train_X, stage1['train_y'], epochs = 50, batch_size = 16, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9989bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_pe.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d656df",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beefd93c",
   "metadata": {},
   "source": [
    "금속분말 데이터셋에 대해서 positional encoding은 좋은 효과가 없었습니다. 모든 머신러닝 방법론이 항상 좋은 성능을 보장하진 않습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd63b8",
   "metadata": {},
   "source": [
    "**[TODO] Stage2 데이터에 대해 positional encoding 적용해보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8961983",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = positional_encoding(stage2['train_X'], 5)\n",
    "test_X = positional_encoding(stage2['test_X'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5fe3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model_pe = ResidualMLP(stage2['train_y'].shape[1], use_residual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc64f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model_pe.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e28be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model_pe.fit(train_X, stage2['train_y'], epochs = 50, batch_size = 16, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_pe.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1697cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d812bc3",
   "metadata": {},
   "source": [
    "## 5. [TODO] 최적의 인공지능 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d63fd4f",
   "metadata": {},
   "source": [
    "여태까지 배운 내용들을 종합하여 금속분말 데이터셋에 대해 최고 성능을 발휘하는 최적의 인공지능 모델을 만들어보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c02895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea73b91",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
