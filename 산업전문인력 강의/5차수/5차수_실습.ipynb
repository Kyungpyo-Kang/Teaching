{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0cc3052",
   "metadata": {},
   "source": [
    "# [실습5] 금속분말 생성공정 최적화를 위한 딥러닝 심화 (정답)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a6b0a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25da0b48",
   "metadata": {},
   "source": [
    "## 실습 목표\n",
    "---\n",
    "- 모델의 일반화에 대해 이해합니다.\n",
    "- 일반화를 위한 방법들을 배워봅니다.\n",
    "- 조기 종료 방법을 배워봅니다.\n",
    "- 가중치 규제 방법을 배워봅니다.\n",
    "- 앙상블 모델을 배워봅니다.\n",
    "- 정규화를 배워봅니다.\n",
    "- 데이터 증강 기법을 배워봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d3b14",
   "metadata": {},
   "source": [
    "## 실습 목차\n",
    "---\n",
    "1. **일반화를 위한 방법들:** 일반화를 위한 여러 방법들을 사용해보고 성능을 비교합니다.\n",
    "\n",
    "2. **조기 종료:** 조기 종료 방법을 수행해보고, 성능을 비교해봅니다,\n",
    "\n",
    "3. **가중치 규제:** 가중치 규제 방법을 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "4. **앙상블 모델:** 앙상블 모델을 구현해봅니다.\n",
    "\n",
    "5. **Dropout:** Dropout을 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "6. **정규화:** 정규화를 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "7. **데이터 증강 기법:** 데이터 증강기법을 수행해보고, 성능을 비교해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c426ef",
   "metadata": {},
   "source": [
    "## 실습 개요\n",
    "---\n",
    "\n",
    "이번 실습에서는 다양한 일반화를 위한 방법들을 수행해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4abd11a",
   "metadata": {},
   "source": [
    "## 1. 일반화를 위한 방법들\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 일반화 방법들을 수행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ef7d1",
   "metadata": {},
   "source": [
    "### 1.1 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import json\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81198a74",
   "metadata": {},
   "source": [
    "### 1.2 데이터셋 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = {\n",
    "    'train_X': np.load('./Data/train_data_stage1_X.npy'),\n",
    "    'train_y': np.load('./Data/train_data_stage1_y.npy'),\n",
    "    'valid_X': np.load('./Data/valid_data_stage1_X.npy'),\n",
    "    'valid_y': np.load('./Data/valid_data_stage1_y.npy'),\n",
    "    'test_X': np.load('./Data/test_data_stage1_X.npy'),\n",
    "    'test_y': np.load('./Data/test_data_stage1_y.npy'),\n",
    "}\n",
    "\n",
    "stage2 = {\n",
    "    'train_X': np.load('./Data/train_data_stage2_X.npy'),\n",
    "    'train_y': np.load('./Data/train_data_stage2_y.npy'),\n",
    "    'valid_X': np.load('./Data/valid_data_stage2_X.npy'),\n",
    "    'valid_y': np.load('./Data/valid_data_stage2_y.npy'),\n",
    "    'test_X': np.load('./Data/test_data_stage2_X.npy'),\n",
    "    'test_y': np.load('./Data/test_data_stage2_y.npy'),\n",
    "}\n",
    "# 뒤에서 사용하지 않으니 메모리 줄이기 위해 삭제\n",
    "# columns = json.load(open('./Data/valid_columns.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cad839",
   "metadata": {},
   "source": [
    "### 1.3 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f91df4",
   "metadata": {},
   "source": [
    "### 1.3.1 Stage1 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c692993",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_X_mean = stage1['train_X'].mean(axis = 0)\n",
    "stage1_y_mean = stage1['train_y'].mean(axis = 0)\n",
    "print('입력값 평균:', stage1_X_mean)\n",
    "print('출력값 평균:', stage1_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_X_std = stage1['train_X'].std(axis = 0)\n",
    "stage1_y_std = stage1['train_y'].std(axis = 0)\n",
    "print('입력값 표준편차:', stage1_X_std)\n",
    "print('출력값 표준편차:', stage1_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3831be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 표준화\n",
    "stage1['train_X'] = (stage1['train_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['train_y'] = (stage1['train_y'] - stage1_y_mean) / stage1_y_std\n",
    "# 검증용 데이터 표준화\n",
    "stage1['valid_X'] = (stage1['valid_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['valid_y'] = (stage1['valid_y'] - stage1_y_mean) / stage1_y_std\n",
    "# 테스트 데이터 표준화\n",
    "stage1['test_X'] = (stage1['test_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['test_y'] = (stage1['test_y'] - stage1_y_mean) / stage1_y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3f935",
   "metadata": {},
   "source": [
    "### 1.3.2 Stage2 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd144c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_X_mean = stage2['train_X'].mean(axis = 0)\n",
    "stage2_y_mean = stage2['train_y'].mean(axis = 0)\n",
    "print('입력값 평균:', stage2_X_mean)\n",
    "print('출력값 평균:', stage2_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_X_std = stage2['train_X'].std(axis = 0)\n",
    "stage2_y_std = stage2['train_y'].std(axis = 0)\n",
    "print('입력값 표준편차:', stage2_X_std)\n",
    "print('출력값 표준편차:', stage2_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 표준화\n",
    "stage2['train_X'] = (stage2['train_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['train_y'] = (stage2['train_y'] - stage2_y_mean) / stage2_y_std\n",
    "\n",
    "# 검증용 데이터 표준화\n",
    "stage2['valid_X'] = (stage2['valid_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['valid_y'] = (stage2['valid_y'] - stage2_y_mean) / stage2_y_std\n",
    "\n",
    "# 테스트 데이터 표준화\n",
    "stage2['test_X'] = (stage2['test_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['test_y'] = (stage2['test_y'] - stage2_y_mean) / stage2_y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f742913",
   "metadata": {},
   "source": [
    "### 1.4 학습 데이터 수에 따른 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31698702",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use = [0.01, 0.1, 0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65f0d8b",
   "metadata": {},
   "source": [
    "학습데이터의 1%, 10%, 50%, 100% 를 사용한 모델의 성능을 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad17109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 총 4회 1%, 10%, 50%, 100% 반복\n",
    "for ratio in data_use:\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    # 모델 정의\n",
    "    MLP_model = tf.keras.Sequential([\n",
    "        Input(shape = stage1['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "    ])\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "    )\n",
    "    \n",
    "    # 학습 데이터 개수\n",
    "    total_data = len(stage1['train_X'])\n",
    "    len_data = int(total_data * ratio)\n",
    "    # 모델 학습\n",
    "    # ratio가 높을 수록 epochs 는 줄어듦 -> 즉, 학습데이터 양에 따라 학습횟수 조절\n",
    "    history = MLP_model.fit(stage1['train_X'][:len_data], stage1['train_y'][:len_data], \n",
    "                            epochs = 50 * int(1 / ratio),\n",
    "                            batch_size = 16, verbose = 0)\n",
    "    pred = MLP_model.predict(stage1['test_X'])\n",
    "    r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "    print(\"R2 score (학습데이터 수: %d): %f\"%(len_data, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b67782",
   "metadata": {},
   "source": [
    "학습데이터가 많을수록 모델의 성능이 좋은 것을 확인하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09fd9e0",
   "metadata": {},
   "source": [
    "## 2. Early stop\n",
    "검증용 데이터를 이용하여 모델이 과적합 되기 전에 학습을 중지해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299323d7",
   "metadata": {},
   "source": [
    "### 2.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# early stop 을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# early stop 을 사용할 모델입니다.\n",
    "MLP_model_es = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eadbde",
   "metadata": {},
   "source": [
    "### 2.2 모델 학습 방법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8492485",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_es.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f895e",
   "metadata": {},
   "source": [
    "### 2.3 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa755dd",
   "metadata": {},
   "source": [
    "먼저, early stop 을 사용하지 않을 모델부터 학습합니다. 실습시간을 고려하여 전체 학습데이터 중 1000개만 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f7354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cbc353",
   "metadata": {},
   "source": [
    "다음으로, early stop을 사용할 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc277d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# valid data를 사용하는 이유: early stopping에서 활용\n",
    "# 학습을 반복할 때마다 test 데이터처럼 사용 -> 임계치 넘어가면 학습 종료\n",
    "# patience: 개선이 없다고 판단하기 전에 대기할 에폭 수. 즉, 이 해당 반복동안 검증 손실이 개선되지 않으면 학습을 중단\n",
    "# default -> 기본값은 0입니다.\n",
    "# 50회 동안 손실이 개선되지 않으면 종료\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
    "history_es = MLP_model_es.fit(stage1['train_X'][:1000], stage1['train_y'][:1000], \n",
    "                           validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                           epochs = 500, batch_size = 16, verbose = 2,\n",
    "                          callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9d126",
   "metadata": {},
   "source": [
    "### 2.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55938ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa89874",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472121d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_es.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39928902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'train w/o EarlyStop')\n",
    "plt.plot(history_es.history['loss'], label = 'train w/ EarlyStop')\n",
    "plt.plot(history.history['val_loss'], label = 'valid w/o EarlyStop')\n",
    "plt.plot(history_es.history['val_loss'], label = 'valid w/ EarlyStop')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd6a31",
   "metadata": {},
   "source": [
    "검증용 데이터셋을 이용하여 early stop 하였을 때 모델의 성능이 더 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794679e3",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 Early stop 을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5da5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# early stop 을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# early stop 을 사용할 모델입니다.\n",
    "MLP_model_es = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 컴파일 합니다.\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_es.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683f94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Early stop 을 적용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500, \n",
    "                        batch_size = 16, \n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e198d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 다음으로, Early stop 을 적용할 모델을 학습합니다.\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
    "history_es = MLP_model_es.fit(stage2['train_X'][:1000], stage2['train_y'][:1000], \n",
    "                           validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                           epochs = 500, batch_size = 16, verbose = 2,\n",
    "                          callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop 을 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop 을 사용한 모델을 평가합니다.\n",
    "pred = MLP_model_es.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a3b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'train w/o EarlyStop')\n",
    "plt.plot(history_es.history['loss'], label = 'train w/ EarlyStop')\n",
    "plt.plot(history.history['val_loss'], label = 'valid w/o EarlyStop')\n",
    "plt.plot(history_es.history['val_loss'], label = 'valid w/ EarlyStop')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb5b4b0",
   "metadata": {},
   "source": [
    "Stage2 의 데이터에 대해서는 early stop을 사용하였을 때, r2-score 가 더 낮은 것을 확인할 수 있습니다. 모든 데이터셋에 대해 특정 방법이 항상 우세하지는 않습니다. 데이터마다 어떠한 방법을 선택하고, 어떤 하이퍼 파라미터를 선택할지 신중하게 선택할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2890fb5b",
   "metadata": {},
   "source": [
    "## 3. 가중치 규제\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 가중치 규제를 모델에 적용해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38132143",
   "metadata": {},
   "source": [
    "### 3.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 가중치 규제를 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 가중치규제를 사용할 모델입니다. L2 regularizer을 적용해봅니다\n",
    "# 규제강도가 커질수록 파라미터가 0에 수렴\n",
    "# 과소적합 위험도 존재\n",
    "MLP_model_reg = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da334b4b",
   "metadata": {},
   "source": [
    "### 3.2 모델 학습 방법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69597ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_reg.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492946",
   "metadata": {},
   "source": [
    "### 3.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f4a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c7ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_reg = MLP_model_reg.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                            validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                            epochs = 500,\n",
    "                            batch_size = 16,\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b31d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_reg.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870bdaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11141337",
   "metadata": {},
   "source": [
    "가중치 규제를 사용한 모델에서 성능이 더 좋았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa05e99",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 가중치규제를 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 가중치 규제를 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 가중치규제를 사용할 모델입니다. L2 regularizer을 적용해봅니다.\n",
    "MLP_model_reg = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 컴파일 합니다.\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_reg.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118fac7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가중치규제를 사용하지 않는 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음으로, 가중치규제를 사용하는 모델을 학습합니다.\n",
    "history_reg = MLP_model_reg.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                            validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                            epochs = 500,\n",
    "                            batch_size = 16,\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8effaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 규제를 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_reg.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0dd66b",
   "metadata": {},
   "source": [
    "## 4. 앙상블 모델\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 앙상블 모델을 학습해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1116b",
   "metadata": {},
   "source": [
    "### 4.1 Weak 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a96b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "n_estimators = 10\n",
    "models = []\n",
    "\n",
    "# Model averaging 방식\n",
    "for i in range(n_estimators):\n",
    "    model = tf.keras.Sequential([\n",
    "        Input(shape = stage1['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "    ])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c1519",
   "metadata": {},
   "source": [
    "### 4.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5344c",
   "metadata": {},
   "source": [
    "### 4.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86024ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len_training_data = len(stage1['train_X'])\n",
    "\n",
    "# 일부 학습데이터만 학습\n",
    "len_subset = int(len_training_data * 0.25)\n",
    "histories =[]\n",
    "idxs = np.arange(len_training_data)\n",
    "for model in models:\n",
    "    train_X = stage1['train_X'][idxs][:len_subset]\n",
    "    train_y = stage1['train_y'][idxs][:len_subset]\n",
    "    history = model.fit(train_X, train_y, epochs = 50, batch_size = 16, verbose = 2)\n",
    "    histories.append(history)\n",
    "    np.random.shuffle(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9be337",
   "metadata": {},
   "source": [
    "### 4.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ffdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 0\n",
    "# 개별 평가\n",
    "for i, model in enumerate(models):\n",
    "    pred = model.predict(stage1['test_X'])\n",
    "    r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "    print(\"%d 번째 weak model - R2 score: %f\"%(i+1, r2))\n",
    "    preds += pred\n",
    "    \n",
    "# 평균\n",
    "preds /= len(models)\n",
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], preds)\n",
    "print(\"앙상블 모델 R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31231f34",
   "metadata": {},
   "source": [
    "앙상블 모델이 각각의 약한 모델보다 성능이 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236c116",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 앙상블을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6429404",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# Weak 모델 정의\n",
    "n_estimators = 10\n",
    "models = []\n",
    "for i in range(n_estimators):\n",
    "    model = tf.keras.Sequential([\n",
    "        Input(shape = stage2['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "    ])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5024f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "for model in models:\n",
    "    model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388806c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "len_training_data = len(stage2['train_X'])\n",
    "len_subset = int(len_training_data * 0.25)\n",
    "histories =[]\n",
    "idxs = np.arange(len_training_data)\n",
    "for model in models:\n",
    "    train_X = stage2['train_X'][idxs][:len_subset]\n",
    "    train_y = stage2['train_y'][idxs][:len_subset]\n",
    "    history = model.fit(train_X, train_y, epochs = 50, batch_size = 16, verbose = 2)\n",
    "    histories.append(history)\n",
    "    np.random.shuffle(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fbd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측 및 평가\n",
    "preds = 0\n",
    "for i, model in enumerate(models):\n",
    "    pred = model.predict(stage2['test_X'])\n",
    "    r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "    print(\"%d 번째 weak model - R2 score: %f\"%(i+1, r2))\n",
    "    preds += pred\n",
    "preds /= len(models)\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], preds)\n",
    "print(\"앙상블 모델 R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f59525",
   "metadata": {},
   "source": [
    "## 5. Dropout\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 Dropout 을 적용해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11386872",
   "metadata": {},
   "source": [
    "### 5.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ebe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# Dropout을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# Dropout을 사용할 모델입니다. rate는 0.2로 설정합니다.\n",
    "MLP_model_dropout = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dropout(rate=0.2), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f95aa",
   "metadata": {},
   "source": [
    "### 5.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f627905",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_dropout.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759b009",
   "metadata": {},
   "source": [
    "### 5.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7ee47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39df34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_dropout = MLP_model_dropout.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                                validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                                epochs = 500,\n",
    "                                batch_size = 16,\n",
    "                                verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a9b91",
   "metadata": {},
   "source": [
    "### 5.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c85ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_dropout.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80beb00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5eb82",
   "metadata": {},
   "source": [
    "Dropout 을 사용한 모델이 더 성능이 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405dfa1",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 Dropout을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab75d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# Dropout을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# Dropout을 사용할 모델입니다. rate는 0.2로 설정합니다.\n",
    "MLP_model_dropout = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dropout(rate=0.2), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_dropout.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e117c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropout 을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b04850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 을 사용할 모델을 학습합니다.\n",
    "history_dropout = MLP_model_dropout.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                                        epochs = 500,\n",
    "                                        batch_size = 16,\n",
    "                                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0562a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 을 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ab93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 을 사용한 않은 모델을 평가합니다.\n",
    "pred = MLP_model_dropout.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e858f",
   "metadata": {},
   "source": [
    "## 6. 정규화\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 정규화를 수행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669612f",
   "metadata": {},
   "source": [
    "### 6.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 정규화를 하지 않을 모델입니다. Dropout에서 학습한 모델과 같은 구조를 사용하겠습니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 정규화를 사용할 모델입니다. Batch normalization 을 사용해보겠습니다.\n",
    "MLP_model_ln = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128), \n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c8cca",
   "metadata": {},
   "source": [
    "### 6.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")\n",
    "MLP_model_ln.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469ed85",
   "metadata": {},
   "source": [
    "### 6.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce3cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 정규화를 사용할 모델을 학습합니다.\n",
    "history_ln = MLP_model_ln.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                           validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                           epochs = 500,\n",
    "                           batch_size = 16,\n",
    "                           verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c0b5f",
   "metadata": {},
   "source": [
    "### 6.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b15d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_ln.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8931504",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439af88",
   "metadata": {},
   "source": [
    "정규화를 사용한 모델에서 성능이 더 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feecf106",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 정규화를 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e935b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "#MLP 모델을 설정합니다.\n",
    "# 정규화를 하지 않을 모델입니다. Dropout에서 학습한 모델과 같은 구조를 사용하겠습니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 정규화를 사용할 모델입니다. Batch normalization 을 사용해보겠습니다.\n",
    "MLP_model_ln = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128), \n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f863df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")\n",
    "MLP_model_ln.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb37cdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 정규화를 사용할 모델을 학습합니다.\n",
    "history = MLP_model_ln.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                           validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                           epochs = 500,\n",
    "                           batch_size = 16,\n",
    "                           verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용한 모델을 평가합니다.\n",
    "pred = MLP_model_ln.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d089ba",
   "metadata": {},
   "source": [
    "## 7. 데이터 증강 기법\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 정규화를 수행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc74c3a",
   "metadata": {},
   "source": [
    "### 7.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 설정합니다.\n",
    "# 데이터 증강을 하지 않을 모델입니다. Dropout에서 학습한 모델을 사용하겠습니다.\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 데이터 증강 기법을 사용할 모델입니다. 데이터에 임의의 가우시안 노이즈를 추가해보겠습니다.\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model_aug = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.GaussianNoise(stddev = 0.1),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92594e30",
   "metadata": {},
   "source": [
    "### 7.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a274bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_aug.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90097180",
   "metadata": {},
   "source": [
    "### 7.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab566ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 증강기법을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbab4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 증강기법을 사용할 모델을 학습합니다.\n",
    "history = MLP_model_aug.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                            validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                            epochs = 500,\n",
    "                            batch_size = 16,\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201ebc2",
   "metadata": {},
   "source": [
    "### 7.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f52b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_aug.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3841c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d1ed4",
   "metadata": {},
   "source": [
    "데이터 증강 기법을 사용한 모델이 성능이 더 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c44f8c",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 데이터 증강기법을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2777899",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 데이터 증강을 하지 않을 모델입니다. Dropout에서 학습한 모델을 사용하겠습니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 데이터 증강 기법을 사용할 모델입니다. 데이터에 임의의 가우시안 노이즈를 추가해보겠습니다.\n",
    "MLP_model_aug = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.GaussianNoise(stddev = 0.1),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd2105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_aug.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강기법을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2465e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강기법을 사용할 모델을 학습합니다.\n",
    "history_aug = MLP_model_aug.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                            validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                            epochs = 500,\n",
    "                            batch_size = 16,\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7793baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용한 모델을 평가합니다.\n",
    "pred = MLP_model_aug.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccc51b",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc866f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
