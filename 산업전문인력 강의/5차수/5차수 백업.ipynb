{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f1d964",
   "metadata": {},
   "source": [
    "# [실습5] 금속분말 생성공정 최적화를 위한 딥러닝 심화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693525e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142d32dc",
   "metadata": {},
   "source": [
    "## 실습 목표\n",
    "---\n",
    "- 모델의 일반화에 대해 이해합니다.\n",
    "- 일반화를 위한 방법들을 배워봅니다.\n",
    "- 조기 종료 방법을 배워봅니다.\n",
    "- 가중치 규제 방법을 배워봅니다.\n",
    "- 앙상블 모델을 배워봅니다.\n",
    "- 정규화를 배워봅니다.\n",
    "- 데이터 증강 기법을 배워봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637dad90",
   "metadata": {},
   "source": [
    "## 실습 목차\n",
    "---\n",
    "1. **일반화를 위한 방법들:** 일반화를 위한 여러 방법들을 사용해보고 성능을 비교합니다.\n",
    "\n",
    "2. **조기 종료:** 조기 종료 방법을 수행해보고, 성능을 비교해봅니다,\n",
    "\n",
    "3. **가중치 규제:** 가중치 규제 방법을 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "4. **앙상블 모델:** 앙상블 모델을 구현해봅니다.\n",
    "\n",
    "5. **Dropout:** Dropout을 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "6. **정규화:** 정규화를 수행해보고, 성능을 비교해봅니다.\n",
    "\n",
    "7. **데이터 증강 기법:** 데이터 증강기법을 수행해보고, 성능을 비교해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0043bb5",
   "metadata": {},
   "source": [
    "## 실습 개요\n",
    "---\n",
    "\n",
    "이번 실습에서는 다양한 일반화를 위한 방법들을 수행해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed02aa",
   "metadata": {},
   "source": [
    "## 1. 일반화를 위한 방법들\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 일반화 방법들을 수행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca17b00",
   "metadata": {},
   "source": [
    "### 1.1 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12baa9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import json\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68633e62",
   "metadata": {},
   "source": [
    "### 1.2 데이터셋 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9516cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1 = {\n",
    "    'train_X': np.load('./Data/train_data_stage1_X.npy'),\n",
    "    'train_y': np.load('./Data/train_data_stage1_y.npy'),\n",
    "    'valid_X': np.load('./Data/valid_data_stage1_X.npy'),\n",
    "    'valid_y': np.load('./Data/valid_data_stage1_y.npy'),\n",
    "    'test_X': np.load('./Data/test_data_stage1_X.npy'),\n",
    "    'test_y': np.load('./Data/test_data_stage1_y.npy'),\n",
    "}\n",
    "\n",
    "stage2 = {\n",
    "    'train_X': np.load('./Data/train_data_stage2_X.npy'),\n",
    "    'train_y': np.load('./Data/train_data_stage2_y.npy'),\n",
    "    'valid_X': np.load('./Data/valid_data_stage2_X.npy'),\n",
    "    'valid_y': np.load('./Data/valid_data_stage2_y.npy'),\n",
    "    'test_X': np.load('./Data/test_data_stage2_X.npy'),\n",
    "    'test_y': np.load('./Data/test_data_stage2_y.npy'),\n",
    "}\n",
    "\n",
    "columns = json.load(open('./Data/valid_columns.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6db0f4",
   "metadata": {},
   "source": [
    "### 1.3 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18a6dc",
   "metadata": {},
   "source": [
    "### 1.3.1 Stage1 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_X_mean = stage1['train_X'].mean(axis = 0)\n",
    "stage1_y_mean = stage1['train_y'].mean(axis = 0)\n",
    "print('입력값 평균:', stage1_X_mean)\n",
    "print('출력값 평균:', stage1_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf15259",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_X_std = stage1['train_X'].std(axis = 0)\n",
    "stage1_y_std = stage1['train_y'].std(axis = 0)\n",
    "print('입력값 표준편차:', stage1_X_std)\n",
    "print('출력값 표준편차:', stage1_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 표준화\n",
    "stage1['train_X'] = (stage1['train_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['train_y'] = (stage1['train_y'] - stage1_y_mean) / stage1_y_std\n",
    "# 검증용 데이터 표준화\n",
    "stage1['valid_X'] = (stage1['valid_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['valid_y'] = (stage1['valid_y'] - stage1_y_mean) / stage1_y_std\n",
    "# 테스트 데이터 표준화\n",
    "stage1['test_X'] = (stage1['test_X'] - stage1_X_mean) / stage1_X_std\n",
    "stage1['test_y'] = (stage1['test_y'] - stage1_y_mean) / stage1_y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136139b",
   "metadata": {},
   "source": [
    "### 1.3.2 Stage2 데이터 표준화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2338de",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_X_mean = stage2['train_X'].mean(axis = 0)\n",
    "stage2_y_mean = stage2['train_y'].mean(axis = 0)\n",
    "print('입력값 평균:', stage2_X_mean)\n",
    "print('출력값 평균:', stage2_y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_X_std = stage2['train_X'].std(axis = 0)\n",
    "stage2_y_std = stage2['train_y'].std(axis = 0)\n",
    "print('입력값 표준편차:', stage2_X_std)\n",
    "print('출력값 표준편차:', stage2_y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa203a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 표준화\n",
    "stage2['train_X'] = (stage2['train_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['train_y'] = (stage2['train_y'] - stage2_y_mean) / stage2_y_std\n",
    "\n",
    "# 검증용 데이터 표준화\n",
    "stage2['valid_X'] = (stage2['valid_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['valid_y'] = (stage2['valid_y'] - stage2_y_mean) / stage2_y_std\n",
    "\n",
    "# 테스트 데이터 표준화\n",
    "stage2['test_X'] = (stage2['test_X'] - stage2_X_mean) / stage2_X_std\n",
    "stage2['test_y'] = (stage2['test_y'] - stage2_y_mean) / stage2_y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e9cb7f",
   "metadata": {},
   "source": [
    "### 1.4 학습 데이터 수에 따른 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use = [0.01, 0.1, 0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4310eff6",
   "metadata": {},
   "source": [
    "학습데이터의 1%, 10%, 50%, 100% 를 사용한 모델의 성능을 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84335165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ratio in data_use:\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "    # 모델 정의\n",
    "    MLP_model = tf.keras.Sequential([\n",
    "        Input(shape = stage1['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "    ])\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "    )\n",
    "    \n",
    "    # 학습 데이터 개수\n",
    "    total_data = len(stage1['train_X'])\n",
    "    len_data = int(total_data * ratio)\n",
    "    # 모델 학습\n",
    "    history = MLP_model.fit(stage1['train_X'][:len_data], stage1['train_y'][:len_data], \n",
    "                            epochs = 50 * int(1 / ratio),\n",
    "                            batch_size = 16, verbose = 0)\n",
    "    pred = MLP_model.predict(stage1['test_X'])\n",
    "    r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "    print(\"R2 score (학습데이터 수: %d): %f\"%(len_data, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d887c34",
   "metadata": {},
   "source": [
    "학습데이터가 많을수록 모델의 성능이 좋은 것을 확인하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a779dad",
   "metadata": {},
   "source": [
    "## 2. Early stop\n",
    "검증용 데이터를 이용하여 모델이 과적합 되기 전에 학습을 중지해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076c03b",
   "metadata": {},
   "source": [
    "### 2.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# early stop 을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# early stop 을 사용할 모델입니다.\n",
    "MLP_model_es = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261cdc55",
   "metadata": {},
   "source": [
    "### 2.2 모델 학습 방법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_es.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e8707",
   "metadata": {},
   "source": [
    "### 2.3 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9aed4",
   "metadata": {},
   "source": [
    "먼저, early stop 을 사용하지 않을 모델부터 학습합니다. 실습시간을 고려하여 전체 학습데이터 중 1000개만 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16561c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff687df",
   "metadata": {},
   "source": [
    "다음으로, early stop을 사용할 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea064ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
    "history_es = MLP_model_es.fit(stage1['train_X'][:1000], stage1['train_y'][:1000], \n",
    "                           validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                           epochs = 500, batch_size = 16, verbose = 2,\n",
    "                          callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a63eed",
   "metadata": {},
   "source": [
    "### 2.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e652459",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e514b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_es.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff94cd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca7127",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'train w/o EarlyStop')\n",
    "plt.plot(history_es.history['loss'], label = 'train w/ EarlyStop')\n",
    "plt.plot(history.history['val_loss'], label = 'valid w/o EarlyStop')\n",
    "plt.plot(history_es.history['val_loss'], label = 'valid w/ EarlyStop')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6e725",
   "metadata": {},
   "source": [
    "검증용 데이터셋을 이용하여 early stop 하였을 때 모델의 성능이 더 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f55bc0f",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 Early stop 을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6670cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# early stop 을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# early stop 을 사용할 모델입니다.\n",
    "MLP_model_es = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9bf573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 컴파일 합니다.\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_es.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfbacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Early stop 을 적용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500, \n",
    "                        batch_size = 16, \n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b241691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 다음으로, Early stop 을 적용할 모델을 학습합니다.\n",
    "es = _____________________\n",
    "history_es = MLP_model_es.fit(________________, _________________, \n",
    "                           validation_data = (____________, ______________),\n",
    "                           epochs = 500, batch_size = 16, verbose = 2,\n",
    "                          callbacks = ____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop 을 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f456f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stop 을 사용한 모델을 평가합니다.\n",
    "pred = ___________________________\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label = 'train w/o EarlyStop')\n",
    "plt.plot(history_es.history['loss'], label = 'train w/ EarlyStop')\n",
    "plt.plot(history.history['val_loss'], label = 'valid w/o EarlyStop')\n",
    "plt.plot(history_es.history['val_loss'], label = 'valid w/ EarlyStop')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7bf800",
   "metadata": {},
   "source": [
    "Stage2 의 데이터에 대해서는 early stop을 사용하였을 때, r2-score 가 더 낮은 것을 확인할 수 있습니다. 모든 데이터셋에 대해 특정 방법이 항상 우세하지는 않습니다. 데이터마다 어떠한 방법을 선택하고, 어떤 하이퍼 파라미터를 선택할지 신중하게 선택할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41c64e",
   "metadata": {},
   "source": [
    "## 3. 가중치 규제\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 가중치 규제를 모델에 적용해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072fe368",
   "metadata": {},
   "source": [
    "### 3.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 가중치 규제를 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 가중치규제를 사용할 모델입니다. L1 regularizer을 적용해봅니다.\n",
    "MLP_model_reg = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48133d8c",
   "metadata": {},
   "source": [
    "### 3.2 모델 학습 방법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_reg.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aab63c",
   "metadata": {},
   "source": [
    "### 3.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e2be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e02cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_reg = MLP_model_reg.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                            validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                            epochs = 500,\n",
    "                            batch_size = 16,\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebf808",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_reg.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132f18f",
   "metadata": {},
   "source": [
    "가중치 규제를 사용한 모델에서 성능이 더 좋았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ec324",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 가중치규제를 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50b8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 가중치 규제를 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 가중치규제를 사용할 모델입니다. L1 regularizer을 적용해봅니다.\n",
    "MLP_model_reg = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu', ___________________________________, \n",
    "    tf.keras.layers.Dense(64, activation = 'relu', ___________________________________,\n",
    "    tf.keras.layers.Dense(32, activation = 'relu', ___________________________________,\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f814224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 컴파일 합니다.\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_reg.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e1fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 가중치규제를 사용하지 않는 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b570b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음으로, 가중치규제를 사용하는 모델을 학습합니다.\n",
    "history_reg = MLP_model_reg.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                            validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                            epochs = 500,\n",
    "                            batch_size = 16,\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 규제를 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c786660",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_reg.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e2ffb",
   "metadata": {},
   "source": [
    "## 4. 앙상블 모델\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 앙상블 모델을 학습해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5daf57",
   "metadata": {},
   "source": [
    "### 4.1 Weak 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "n_estimators = 10\n",
    "models = []\n",
    "for i in range(n_estimators):\n",
    "    model = tf.keras.Sequential([\n",
    "        Input(shape = stage1['train_X'].shape[1]),\n",
    "        tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "    ])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c862d4",
   "metadata": {},
   "source": [
    "### 4.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb64213",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186991a0",
   "metadata": {},
   "source": [
    "### 4.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce592e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len_training_data = len(stage1['train_X'])\n",
    "len_subset = int(len_training_data * 0.25)\n",
    "histories =[]\n",
    "idxs = np.arange(len_training_data)\n",
    "for model in models:\n",
    "    train_X = stage1['train_X'][idxs][:len_subset]\n",
    "    train_y = stage1['train_y'][idxs][:len_subset]\n",
    "    history = model.fit(train_X, train_y, epochs = 50, batch_size = 16, verbose = 2)\n",
    "    histories.append(history)\n",
    "    np.random.shuffle(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b5bbb",
   "metadata": {},
   "source": [
    "### 4.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 0\n",
    "for i, model in enumerate(models):\n",
    "    pred = model.predict(stage1['test_X'])\n",
    "    r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "    print(\"%d 번째 weak model - R2 score: %f\"%(i+1, r2))\n",
    "    preds += pred\n",
    "preds /= len(models)\n",
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], preds)\n",
    "print(\"앙상블 모델 R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4e6ae",
   "metadata": {},
   "source": [
    "앙상블 모델이 각각의 약한 모델보다 성능이 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4b462",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 앙상블을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077eafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# Weak 모델 정의\n",
    "n_estimators = 10\n",
    "models = []\n",
    "# Stage1 에 사용했던 앙상블 모델을 그대로 사용해봅시다.\n",
    "for i in range(n_estimators):\n",
    "    model = tf.keras.Sequential([\n",
    "        Input(shape = stage2['train_X'].shape[1]),\n",
    "        ___________________________________,\n",
    "        ___________________________________,\n",
    "        tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "    ])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a009eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "for model in models:\n",
    "    model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce972bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "len_training_data = len(stage2['train_X'])\n",
    "len_subset = int(len_training_data * 0.25)\n",
    "histories =[]\n",
    "idxs = np.arange(len_training_data)\n",
    "for model in models:\n",
    "    train_X = _________________________\n",
    "    train_y = _________________________\n",
    "    history = model.fit(train_X, train_y, epochs = 50, batch_size = 16, verbose = 2)\n",
    "    histories.append(history)\n",
    "    np.random.shuffle(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f92912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측 및 평가\n",
    "preds = 0\n",
    "for i, model in enumerate(models):\n",
    "    pred = model.predict(stage2['test_X'])\n",
    "    r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "    print(\"%d 번째 weak model - R2 score: %f\"%(i+1, r2))\n",
    "    preds += pred\n",
    "preds /= len(models)\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], preds)\n",
    "print(\"앙상블 모델 R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e6c8a3",
   "metadata": {},
   "source": [
    "## 5. Dropout\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 Dropout 을 적용해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eea715",
   "metadata": {},
   "source": [
    "### 5.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce797fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# Dropout을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# Dropout을 사용할 모델입니다. rate는 0.2로 설정합니다.\n",
    "MLP_model_dropout = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dropout(rate=0.2), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4bf16",
   "metadata": {},
   "source": [
    "### 5.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ce540",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_dropout.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b7963e",
   "metadata": {},
   "source": [
    "### 5.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4fbd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b1fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_dropout = MLP_model_dropout.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                                validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                                epochs = 500,\n",
    "                                batch_size = 16,\n",
    "                                verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543c0c2",
   "metadata": {},
   "source": [
    "### 5.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fa315",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_dropout.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b89c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e8444",
   "metadata": {},
   "source": [
    "Dropout 을 사용한 모델이 더 성능이 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7f4b8",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 Dropout을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072640f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# Dropout을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# Dropout을 사용할 모델입니다. rate는 0.2로 설정합니다.\n",
    "MLP_model_dropout = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    ___________________________________, \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    ___________________________________,\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    ___________________________________,\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_dropout.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2b802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropout 을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 을 사용할 모델을 학습합니다.\n",
    "history_dropout = MLP_model_dropout.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                                        epochs = 500,\n",
    "                                        batch_size = 16,\n",
    "                                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 을 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8345b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 을 사용한 않은 모델을 평가합니다.\n",
    "pred = MLP_model_dropout.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3110c",
   "metadata": {},
   "source": [
    "## 6. 정규화\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 정규화를 수행해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8399d8c9",
   "metadata": {},
   "source": [
    "### 6.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 정규화를 하지 않을 모델입니다. Dropout에서 학습한 모델과 같은 구조를 사용하겠습니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 정규화를 사용할 모델입니다. Batch normalization 을 사용해보겠습니다.\n",
    "MLP_model_ln = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128), \n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.BatchNormalization(), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3908572",
   "metadata": {},
   "source": [
    "### 6.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84af37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")\n",
    "MLP_model_ln.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67776b83",
   "metadata": {},
   "source": [
    "### 6.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4148b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c79932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 정규화를 사용할 모델을 학습합니다.\n",
    "history_ln = MLP_model_ln.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                           validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                           epochs = 500,\n",
    "                           batch_size = 16,\n",
    "                           verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6025062",
   "metadata": {},
   "source": [
    "### 6.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef35473",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e736498",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_ln.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e7464",
   "metadata": {},
   "source": [
    "정규화를 사용한 모델에서 성능이 더 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4bb50",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 정규화를 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f081ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "#MLP 모델을 설정합니다.\n",
    "# 정규화를 하지 않을 모델입니다. \n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128), \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 정규화를 사용할 모델입니다. Batch normalization 을 사용해보겠습니다.\n",
    "MLP_model_ln = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128), \n",
    "    ___________________________________, \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    ___________________________________, \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    ___________________________________, \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95034a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")\n",
    "MLP_model_ln.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff686f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 정규화를 사용할 모델을 학습합니다.\n",
    "history = MLP_model_ln.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                           validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                           epochs = 500,\n",
    "                           batch_size = 16,\n",
    "                           verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7600c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용하지 않은 모델을 평가합니다.\n",
    "pred = MLP_model.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용한 모델을 평가합니다.\n",
    "pred = MLP_model_ln.predict(stage2['test_X'])\n",
    "r2 = sklearn.metrics.r2_score(stage2['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f7cd25",
   "metadata": {},
   "source": [
    "## 7. 데이터 증강 기법\n",
    "---\n",
    "금속분말 데이터셋을 이용하여 정규화를 수행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad5e57",
   "metadata": {},
   "source": [
    "### 7.1 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5535c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델을 설정합니다.\n",
    "# 데이터 증강을 하지 않을 모델입니다.\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 데이터 증강 기법을 사용할 모델입니다. 데이터에 임의의 가우시안 노이즈를 추가해보겠습니다.\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "MLP_model_aug = tf.keras.Sequential([\n",
    "    Input(shape = stage1['train_X'].shape[1]),\n",
    "    tf.keras.layers.GaussianNoise(stddev = 0.1),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage1['train_y'].shape[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f3cf0",
   "metadata": {},
   "source": [
    "### 7.2 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_aug.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584447fe",
   "metadata": {},
   "source": [
    "### 7.3 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29790220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 증강기법을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                        validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c0f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 증강기법을 사용할 모델을 학습합니다.\n",
    "history = MLP_model_aug.fit(stage1['train_X'][:1000], stage1['train_y'][:1000],\n",
    "                            validation_data = (stage1['valid_X'], stage1['valid_y']),\n",
    "                            epochs = 500,\n",
    "                            batch_size = 16,\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c9848",
   "metadata": {},
   "source": [
    "### 7.4 모델 예측 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87456363",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d78f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = MLP_model_aug.predict(stage1['test_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = sklearn.metrics.r2_score(stage1['test_y'], pred)\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648cce7",
   "metadata": {},
   "source": [
    "데이터 증강 기법을 사용한 모델이 성능이 더 좋은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e2e07",
   "metadata": {},
   "source": [
    "### [TODO] Stage2에 대해 데이터 증강기법을 적용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a849c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# MLP 모델을 설정합니다.\n",
    "# 데이터 증강을 하지 않을 모델입니다.\n",
    "MLP_model = tf.keras.Sequential([\n",
    "    Input(shape = stage2['train_X'].shape[1]),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(stage2['train_y'].shape[1])\n",
    "])\n",
    "\n",
    "# 데이터 증강 기법을 사용할 모델입니다. 데이터에 Stage1에서 추가했던 가우시안 노이즈를 추가해보겠습니다.\n",
    "MLP_model_aug = ______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3413ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "MLP_model.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")\n",
    "MLP_model_aug.compile(loss = 'mse',\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강기법을 사용하지 않을 모델을 학습합니다.\n",
    "history = MLP_model.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                        validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                        epochs = 500,\n",
    "                        batch_size = 16,\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강기법을 사용할 모델을 학습합니다.\n",
    "history_aug = MLP_model_aug.fit(stage2['train_X'][:1000], stage2['train_y'][:1000],\n",
    "                            validation_data = (stage2['valid_X'], stage2['valid_y']),\n",
    "                            epochs = 500,\n",
    "                            batch_size = 16,\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ebafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용하지 않은 모델을 평가합니다.\n",
    "pred = ________________________________\n",
    "r2 = ________________________________\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화를 사용한 모델을 평가합니다.\n",
    "pred = ________________________________\n",
    "r2 = ________________________________\n",
    "print(\"R2 score: %f\"%r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12448e63",
   "metadata": {},
   "source": [
    "<span style=\"color:rgb(120, 120, 120)\">본 학습 자료를 포함한 사이트 내 모든 자료의 저작권은 엘리스에 있으며 외부로의 무단 복제, 배포 및 전송을 불허합니다.\n",
    "\n",
    "Copyright @ elice all rights reserved</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109fa84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
